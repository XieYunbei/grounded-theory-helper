import streamlit as st
import pandas as pd
import numpy as np
import altair as alt
from sklearn.cluster import AgglomerativeClustering
from sklearn.metrics.pairwise import cosine_similarity
from openai import OpenAI
import json
import time
import random
import os
import glob
from collections import Counter
from itertools import combinations
from difflib import SequenceMatcher
import platform
import datetime
import copy

# å°è¯•å¯¼å…¥æ‹–æ‹½åº“
try:
    from streamlit_sortables import sort_items
    HAS_SORTABLE = True
except ImportError:
    HAS_SORTABLE = False

# =======================================================================
# 0. æ ¸å¿ƒå·¥å…·å‡½æ•° & æ•°æ®åŠ è½½æ¨¡å—
# =======================================================================

RECOVERY_DIR = "recovery_data_visual_analysis"

def ensure_recovery_dir():
    if not os.path.exists(RECOVERY_DIR):
        os.makedirs(RECOVERY_DIR)

def load_from_jsonl(filepath):
    records = []
    if os.path.exists(filepath):
        with open(filepath, "r", encoding="utf-8") as f:
            for line in f:
                try:
                    if line.strip(): records.append(json.loads(line))
                except: continue
    
    flat_codes = []
    for r in records:
        idx = r.get('original_row_index')
        codes_list = r.get('generated_codes', [])
        source_file = r.get('source_file', 'unknown')
        if isinstance(codes_list, list):
            for c in codes_list:
                if isinstance(c, dict):
                    flat_codes.append({
                        'source_file': source_file,
                        'original_row_index': idx,
                        # å®Œæ•´ä¿ç•™å››åˆ—çŠ¶æ€
                        'original_code': c.get('original_code', c.get('code')),
                        'peer_code': c.get('peer_code', None),
                        'aligned_code': c.get('aligned_code', c.get('code')),
                        'code': c.get('code'), # æœ€ç»ˆåˆ—
                        'quote': c.get('quote'),
                        'confidence': c.get('confidence', 0)
                    })
    return pd.DataFrame(flat_codes)

def save_current_progress(df):
    """ä¿å­˜å…¨é‡çŠ¶æ€"""
    if df.empty: return None
    ensure_recovery_dir()
    date_str = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"VisualAnalysis_Full_{date_str}.jsonl"
    filepath = os.path.join(RECOVERY_DIR, filename)
    
    if 'original_row_index' in df.columns:
        grouped = df.groupby('original_row_index')
        with open(filepath, "w", encoding="utf-8") as f:
            for idx, group in grouped:
                first_row = group.iloc[0]
                codes_list = []
                for _, row in group.iterrows():
                    codes_list.append({
                        "original_code": row.get('original_code'),
                        "peer_code": row.get('peer_code'),
                        "aligned_code": row.get('aligned_code'),
                        "code": row['code'], 
                        "quote": row['quote'],
                        "confidence": row.get('confidence', 0)
                    })
                record = {
                    "original_row_index": int(idx) if pd.notna(idx) else None,
                    "source_file": first_row.get('source_file', 'unknown'),
                    "generated_codes": codes_list,
                    "timestamp": datetime.datetime.now().isoformat()
                }
                f.write(json.dumps(record, ensure_ascii=False) + "\n")
        return filename
    return None

# [NEW] æ’¤é”€ç³»ç»Ÿ (Undo System)
def push_history(action_name="Unknown Action"):
    """åœ¨ä¿®æ”¹æ•°æ®å‰è°ƒç”¨ï¼Œä¿å­˜å½“å‰çŠ¶æ€å¿«ç…§"""
    if 'history_stack' not in st.session_state:
        st.session_state.history_stack = []
    
    # é™åˆ¶æ ˆæ·±åº¦ï¼Œé˜²æ­¢å†…å­˜çˆ†ç‚¸ (å­˜æœ€è¿‘ 10 æ­¥)
    if len(st.session_state.history_stack) >= 10:
        st.session_state.history_stack.pop(0)
    
    snapshot = {
        'open_codes': st.session_state.open_codes.copy(deep=True),
        'axial_codes_df': st.session_state.axial_codes_df.copy(deep=True),
        'desc': action_name,
        'time': time.strftime("%H:%M:%S")
    }
    st.session_state.history_stack.append(snapshot)

def perform_undo():
    """æ‰§è¡Œæ’¤é”€"""
    if 'history_stack' in st.session_state and st.session_state.history_stack:
        last_state = st.session_state.history_stack.pop()
        st.session_state.open_codes = last_state['open_codes']
        st.session_state.axial_codes_df = last_state['axial_codes_df']
        st.toast(f"å·²æ’¤é”€: {last_state['desc']}")
        time.sleep(0.5)
        st.rerun()
    else:
        st.warning("æ²¡æœ‰å¯æ’¤é”€çš„æ“ä½œ")

@st.cache_data(show_spinner=False)
def get_embeddings_dashscope(text_list, api_key):
    if not text_list: return []
    client = OpenAI(
        api_key=api_key, 
        base_url="https://dashscope.aliyuncs.com/compatible-mode/v1"
    )
    all_embeddings = []
    batch_size = 10
    for i in range(0, len(text_list), batch_size):
        batch = text_list[i:i+batch_size]
        try:
            resp = client.embeddings.create(
                model="text-embedding-v2", 
                input=batch
            )
            batch_emb = [d.embedding for d in resp.data]
            all_embeddings.extend(batch_emb)
        except Exception as e:
            st.error(f"Embedding API Error: {e}")
            return []
    return np.array(all_embeddings)

def perform_clustering(codes, embeddings, n_clusters=None, distance_threshold=0.6):
    if len(codes) < 2: return {0: codes}
    clustering = AgglomerativeClustering(
        n_clusters=None, 
        distance_threshold=distance_threshold, 
        metric='cosine', 
        linkage='average'
    )
    labels = clustering.fit_predict(embeddings)
    clusters = {}
    for code, label in zip(codes, labels):
        if label not in clusters: clusters[label] = []
        clusters[label].append(code)
    return clusters

def find_synonym_groups(codes, embeddings, threshold=0.85):
    if len(codes) < 2: return {}
    clustering = AgglomerativeClustering(
        n_clusters=None,
        distance_threshold=1-threshold,
        metric='cosine',
        linkage='average'
    )
    labels = clustering.fit_predict(embeddings)
    groups = {}
    for i, (code, label) in enumerate(zip(codes, labels)):
        if label not in groups: groups[label] = {"codes": [], "indices": []}
        groups[label]["codes"].append(code)
        groups[label]["indices"].append(i)
    result_groups = {}
    for lbl, data in groups.items():
        if len(data["codes"]) > 1:
            if len(data["indices"]) > 1:
                group_emb = embeddings[data["indices"]]
                sim_matrix = cosine_similarity(group_emb)
                avg_sim = np.mean(sim_matrix[np.triu_indices(len(sim_matrix), k=1)])
            else: avg_sim = 1.0
            result_groups[lbl] = {"codes": data["codes"], "score": avg_sim}
    return result_groups

# [OPTIMIZED] ä¼˜åŒ–åçš„å¯¹é½ç®—æ³• (åŠ é€Ÿç‰ˆ)
def align_records_by_quote(df_mine, df_theirs, match_threshold=0.6):
    theirs_records = df_theirs.to_dict('records')
    alignment = []
    mine_records = df_mine.to_dict('records')
    
    # é¢„å¤„ç†ï¼šæ„å»ºç”±å¼•æ–‡é•¿åº¦ç´¢å¼•çš„åˆ—è¡¨ï¼Œå‡å°‘éå†èŒƒå›´
    # ç®€å•åˆ†æ¡¶ï¼šæŒ‰é•¿åº¦åˆ†æ¡¶ï¼Œæ­¥é•¿ä¸º 10
    theirs_buckets = {}
    for r in theirs_records:
        q_len = len(str(r.get('quote', '')))
        bucket_id = q_len // 10
        if bucket_id not in theirs_buckets: theirs_buckets[bucket_id] = []
        theirs_buckets[bucket_id].append(r)
    
    for my_row in mine_records:
        my_quote = str(my_row.get('quote', ''))
        my_len = len(my_quote)
        my_bucket = my_len // 10
        my_code = str(my_row.get('code', ''))
        
        best_match = None
        best_ratio = 0
        
        # åªæœç´¢é•¿åº¦ç›¸è¿‘çš„æ¡¶ (å‰åå„æ‰©1ä¸ªæ¡¶)
        candidates = []
        for b in [my_bucket-1, my_bucket, my_bucket+1]:
            if b in theirs_buckets:
                candidates.extend(theirs_buckets[b])
        
        # å¦‚æœæ¡¶ç­–ç•¥æ¼äº†ï¼ˆæˆ–è€…quoteæçŸ­/æé•¿ï¼‰ï¼Œåˆ™å…¨é‡å…œåº•ï¼Ÿ
        # ä¸ºäº†æ€§èƒ½ï¼Œè¿™é‡Œå‡è®¾å¼•æ–‡é•¿åº¦å·®å¼‚ä¸ä¼šå¤ªå¤§ã€‚å¦‚æœcandidatesä¸ºç©ºï¼Œåˆ™æ‰©å¤§æœç´¢æˆ–å…¨é‡
        if not candidates: 
            candidates = theirs_records # Fallback
            
        # è¿›ä¸€æ­¥ä¼˜åŒ–ï¼šå­—é¢äº¤é›†é¢„ç­› (Jaccard Pre-filter)
        # åªæœ‰å½“å­—ç¬¦äº¤é›†å¤§äºä¸€å®šæ¯”ä¾‹æ‰è¿›è¡Œ SequenceMatcher
        my_char_set = set(my_quote)
        
        for their_row in candidates:
            their_quote = str(their_row.get('quote', ''))
            
            # å¿«é€Ÿ Jaccard æ£€æŸ¥
            if not my_quote and not their_quote:
                ratio = 1.0
            else:
                their_char_set = set(their_quote)
                intersection = len(my_char_set & their_char_set)
                union = len(my_char_set | their_char_set)
                jaccard = intersection / union if union > 0 else 0
                
                # å¦‚æœ Jaccard è¿ 0.3 éƒ½ä¸åˆ°ï¼ŒSequenceMatcher è‚¯å®šä¹Ÿå¾ˆä½ï¼Œè·³è¿‡
                if jaccard < 0.3: 
                    continue
                    
                # æ˜‚è´µçš„è®¡ç®—
                ratio = SequenceMatcher(None, my_quote, their_quote).ratio()
            
            if ratio > best_ratio:
                best_ratio = ratio
                best_match = their_row
        
        status = "unique"
        their_code = None
        if best_ratio >= match_threshold:
            their_code = str(best_match.get('code', ''))
            # æ­¤æ—¶æ¯”è¾ƒçš„æ˜¯ my_code (å¯èƒ½å·²ä¿®æ”¹) å’Œ their_code
            # æ³¨æ„ï¼šå¯¹é½æ—¶ä¸»è¦çœ‹å·®å¼‚ï¼Œè¿™é‡Œæ ‡è®° conflict
            if my_code.strip() == their_code.strip(): status = "agreed"
            else: status = "conflict"
        
        alignment.append({
            "quote": my_quote, "my_code": my_code, "their_code": their_code,
            "status": status, "similarity": best_ratio,
            "raw_row_idx": my_row.get('original_row_index')
        })
    return alignment

def generate_html_tag_cloud(df):
    if df.empty or 'code' not in df.columns: return "æ— æ•°æ®"
    counts = df['code'].value_counts()
    if counts.empty: return "æ— æœ‰æ•ˆæ ‡ç­¾"
    max_count = counts.max()
    min_count = counts.min()
    tags_html = ""
    colors = ['#4a90e2', '#50e3c2', '#b8e986', '#f5a623', '#f8e71c', '#d0021b', '#9013fe', '#4a4a4a']
    for code, count in counts.items():
        size = 14 if max_count == min_count else 12 + (count - min_count) / (max_count - min_count) * 24
        color = random.choice(colors)
        tags_html += f"""<span style="font-size: {size}px; color: {color}; margin: 5px; padding: 5px; 
            display: inline-block; border: 1px solid #eee; border-radius: 5px; background-color: #fafafa;"
            title="å‡ºç°é¢‘æ¬¡: {count}">{code}</span>"""
    return f"<div style='line-height: 2.0; text-align: center; padding: 20px; background: white; border-radius: 10px; border: 1px solid #eee;'>{tags_html}</div>"

def reset_analysis_state():
    keys = ['embeddings', 'clusters_cache', 'sortable_items', 'merge_groups', 'alignment_results', 'page_num_align']
    for k in keys:
        if k in st.session_state: del st.session_state[k]

# =======================================================================
# 1. é¡µé¢é…ç½®ä¸ CSS
# =======================================================================
st.set_page_config(page_title="åˆ†æå·¥ä½œå°", layout="wide")

st.markdown("""
<style>
    [data-testid="stAppViewContainer"] { background-color: #FDFBF5; }
    .quote-box {
        background-color: #f9f9f9;
        border-left: 4px solid #B0C4DE;
        padding: 10px;
        margin-bottom: 10px;
        font-family: "SimSun", "Times New Roman", serif;
        font-size: 1.1rem;
        line-height: 1.6;
        color: #333;
    }
    .quote-label {
        font-size: 0.8rem;
        color: #888;
        margin-bottom: 4px;
        font-weight: bold;
    }
    .stSortable > div > div {
        background-color: #E6F7FF !important; border: 1px solid #69C0FF !important; color: #003a8c !important; 
        border-radius: 6px !important; font-size: 1.1rem !important; font-weight: 600 !important;
        padding: 10px !important; margin-bottom: 8px !important;
        white-space: normal !important; line-height: 1.4 !important;
        box-shadow: 0 2px 4px rgba(0,0,0,0.05) !important;
    }
    .custom-card-hint {
        background-color: #E6F7FF; border: 1px solid #91D5FF; border-radius: 6px;
        padding: 12px; color: #0050B3; font-size: 1rem; margin-bottom: 15px;
    }
</style>
""", unsafe_allow_html=True)

st.title("ğŸ§© åˆ†æå·¥ä½œå°ï¼šæ¸…æ´—ã€å¯¹é½ä¸å½’ç±»")

# çŠ¶æ€åˆå§‹åŒ–
if 'axial_codes_df' not in st.session_state:
    st.session_state.axial_codes_df = pd.DataFrame(columns=['code', 'category', 'confidence', 'reasoning', 'status'])
if 'clusters_cache' not in st.session_state: st.session_state.clusters_cache = None
if 'history_stack' not in st.session_state: st.session_state.history_stack = []

# æ•°æ®åŠ è½½
data_missing = 'open_codes' not in st.session_state or st.session_state.open_codes is None or st.session_state.open_codes.empty
data_invalid = False
if not data_missing:
    if 'code' not in st.session_state.open_codes.columns: data_invalid = True

if data_missing or data_invalid:
    if data_invalid: st.warning("âš ï¸ æ•°æ®æ ¼å¼é”™è¯¯ï¼ˆç¼ºå°‘ 'code' åˆ—ï¼‰ã€‚")
    else: st.info("ğŸ‘‹ è¯·ä¸Šä¼ æ•°æ®ä»¥å¼€å§‹åˆ†æã€‚")
    uploaded_file = st.file_uploader("ğŸ“‚ ä¸Šä¼ å¼€æ”¾ç¼–ç ç»“æœè¡¨ (Excel/CSV)", type=['xlsx', 'csv'], key="primary_uploader")
    if uploaded_file:
        try:
            if uploaded_file.name.endswith('.csv'): df_load = pd.read_csv(uploaded_file)
            else: df_load = pd.read_excel(uploaded_file)
            if 'code' not in df_load.columns: st.error("æ–‡ä»¶ç¼ºå°‘ 'code' åˆ—ã€‚"); st.stop()
            
            # [INIT] åˆå§‹åŒ–4åˆ—ç»“æ„
            if 'original_row_index' not in df_load.columns:
                df_load['original_row_index'] = range(len(df_load))
                
            if 'original_code' not in df_load.columns: df_load['original_code'] = df_load['code']
            if 'peer_code' not in df_load.columns: df_load['peer_code'] = None
            if 'aligned_code' not in df_load.columns: df_load['aligned_code'] = df_load['code']
            
            st.session_state.open_codes = df_load
            reset_analysis_state() 
            st.success("âœ… æ•°æ®åŠ è½½æˆåŠŸï¼")
            time.sleep(1); st.rerun()
        except Exception as e: st.error(f"è¯»å–å¤±è´¥: {e}"); st.stop()
    else: st.stop()

# ç¡®ä¿åˆ—å­˜åœ¨
df = st.session_state.open_codes
for col in ['original_code', 'peer_code', 'aligned_code', 'original_row_index']:
    if col not in df.columns:
        if col == 'peer_code': df[col] = None
        elif col == 'original_row_index': df[col] = range(len(df))
        else: df[col] = df['code']
st.session_state.open_codes = df 

unique_codes = df['code'].dropna().unique().tolist()

# ä¾§è¾¹æ ä¸API
with st.sidebar:
    st.header("ğŸ“‚ è¿›åº¦ç®¡ç†")
    
    # [NEW] æ’¤é”€æŒ‰é’®
    if st.session_state.history_stack:
        if st.button(f"â†©ï¸ æ’¤é”€ä¸Šä¸€æ­¥ ({len(st.session_state.history_stack)})", type="primary", width="stretch"):
            perform_undo()
    else:
        st.button("â†©ï¸ æ’¤é”€ (æ— è®°å½•)", disabled=True, width="stretch")
    
    st.divider()
    
    if os.path.exists(RECOVERY_DIR):
        jsonl_files = glob.glob(os.path.join(RECOVERY_DIR, "*.jsonl"))
        jsonl_files.sort(key=os.path.getmtime, reverse=True)
        if jsonl_files:
            with st.expander("ğŸ“¥ åŠ è½½å†å²è¿›åº¦", expanded=True):
                selected_file = st.selectbox("é€‰æ‹©å†å²æ–‡ä»¶", [os.path.basename(f) for f in jsonl_files], index=0)
                if st.button("ğŸ”„ è½½å…¥é€‰ä¸­æ–‡ä»¶", width="stretch"):
                    filepath = os.path.join(RECOVERY_DIR, selected_file)
                    df_loaded = load_from_jsonl(filepath)
                    if not df_loaded.empty:
                        st.session_state.open_codes = df_loaded
                        reset_analysis_state() 
                        st.success(f"æˆåŠŸè½½å…¥ï¼")
                        time.sleep(1); st.rerun()
    
    st.divider()
    with st.expander("ğŸ”‘ API Key è®¾ç½®", expanded=not bool(st.session_state.get('api_key'))):
        val = st.session_state.get('api_key', '')
        new_key = st.text_input("DashScope Key", value=val, type="password")
        if new_key != val:
            st.session_state.api_key = new_key
            st.success("Key å·²æ›´æ–°")
            
api_ready = bool(st.session_state.get('api_key'))

# =======================================================================
# ä¸»é€‰é¡¹å¡å¸ƒå±€
# =======================================================================
tab_align, tab_clean, tab_kanban = st.tabs(["ğŸ¤ é˜Ÿå‹å¯¹é½ (åˆ†æ­§è§£å†³)", "ğŸ§¹ æ ‡ç­¾æ¸…æ´— (åŒä¹‰åˆå¹¶)", "ğŸ§± ç§¯æœ¨å½’ç±» (è½´å¿ƒåˆ†æ)"])

# -----------------------------------------------------------------------
# TAB 1: é˜Ÿå‹å¯¹é½
# -----------------------------------------------------------------------
with tab_align:
    st.caption("ä¸Šä¼ é˜Ÿå‹çš„ç¼–ç æ–‡ä»¶ï¼ŒAIå°†è‡ªåŠ¨å¯¹é½å¹¶åˆ—å‡ºå·®å¼‚ã€‚")
    file_peer = st.file_uploader("ä¸Šä¼ é˜Ÿå‹æ–‡ä»¶", type=['xlsx', 'csv', 'jsonl'])
    
    if file_peer:
        try:
            if file_peer.name.endswith('.csv'): df_peer = pd.read_csv(file_peer)
            elif file_peer.name.endswith('.jsonl'): df_peer = pd.read_json(file_peer, lines=True)
            else: df_peer = pd.read_excel(file_peer)
            
            if 'alignment_results' not in st.session_state or st.button("ğŸ”„ é‡æ–°å¯¹æ¯”"):
                with st.spinner("æ­£åœ¨å¿«é€Ÿæ¯”å¯¹... (å·²å¯ç”¨æ€§èƒ½ä¼˜åŒ–)"):
                    results = align_records_by_quote(df, df_peer)
                    st.session_state.alignment_results = results
                    
                    # å¼ºåŠ›å›å¡« peer_code
                    push_history("åŒæ­¥é˜Ÿå‹ç¼–ç ") # ä¿å­˜çŠ¶æ€
                    updates = 0
                    for r in results:
                        if r['raw_row_idx'] is not None and str(r['raw_row_idx']) in df['original_row_index'].astype(str).values:
                             mask = df['original_row_index'].astype(str) == str(r['raw_row_idx'])
                             st.session_state.open_codes.loc[mask, 'peer_code'] = r['their_code']
                             updates += 1
                        elif r['quote']:
                             mask = st.session_state.open_codes['quote'] == r['quote']
                             st.session_state.open_codes.loc[mask, 'peer_code'] = r['their_code']
                             updates += 1
                    
                    if updates > 0:
                        save_current_progress(st.session_state.open_codes)
                        st.toast(f"å·²åŒæ­¥ {updates} æ¡é˜Ÿå‹æ•°æ®")
            
            results = st.session_state.alignment_results
            conflicts = [r for r in results if r['status'] == 'conflict']
            
            if conflicts:
                st.warning(f"å‘ç° {len(conflicts)} å¤„åˆ†æ­§")
                page_size = 4
                if 'page_num_align' not in st.session_state: st.session_state.page_num_align = 0
                start_idx = st.session_state.page_num_align * page_size
                current_batch = conflicts[start_idx:start_idx+page_size]
                
                st.progress(min(1.0, (start_idx + len(current_batch)) / len(conflicts)))
                
                for i, item in enumerate(current_batch):
                    idx_real = start_idx + i
                    with st.container(border=True):
                        st.markdown(f"<div class='quote-box'>{item['quote']}</div>", unsafe_allow_html=True)
                        c1, c2 = st.columns(2)
                        with c1:
                            st.info(f"ğŸ‘¤ æˆ‘: **{item['my_code']}**")
                            if st.button("ğŸ‘ˆ ä¿ç•™æˆ‘çš„", key=f"k_my_{idx_real}", width="stretch"):
                                item['status'] = 'resolved'; st.rerun()
                        with c2:
                            st.warning(f"ğŸ‘¥ ä»–: **{item['their_code']}**")
                            if st.button("ğŸ‘‰ é‡‡çº³é˜Ÿå‹", key=f"k_th_{idx_real}", width="stretch"):
                                push_history(f"é‡‡çº³é˜Ÿå‹ç¼–ç : {item['their_code']}") # Undo
                                mask = (st.session_state.open_codes['quote'] == item['quote']) & \
                                       (st.session_state.open_codes['original_code'] == item['my_code'])
                                if mask.any():
                                    st.session_state.open_codes.loc[mask, 'aligned_code'] = item['their_code']
                                    st.session_state.open_codes.loc[mask, 'code'] = item['their_code']
                                    save_current_progress(st.session_state.open_codes)
                                    item['status'] = 'resolved'; st.success("å·²æ›´æ–°"); time.sleep(0.5); st.rerun()
                                else: st.error("å®šä½å¤±è´¥")
                        
                        ai_k = f"ai_adv_{idx_real}"
                        custom_code = st.text_input("âœï¸ ä¿®æ”¹ä¸º", value=st.session_state.get(ai_k, item['my_code']), key=f"inp_{idx_real}")
                        ca, cb = st.columns([1, 2])
                        with ca:
                            if st.button("ğŸ¤– é—®AI", key=f"ask_{idx_real}", disabled=not api_ready):
                                prompt = f"å¼•æ–‡ï¼š{item['quote']}\næ ‡ç­¾Aï¼š{item['my_code']}\næ ‡ç­¾Bï¼š{item['their_code']}\nè¯·ç»™å‡ºä¸€ä¸ªæœ€å‡†ç¡®çš„ç®€çŸ­æ ‡ç­¾ï¼š"
                                try:
                                    client = OpenAI(api_key=st.session_state.api_key, base_url="https://dashscope.aliyuncs.com/compatible-mode/v1")
                                    res = client.chat.completions.create(model="qwen-plus", messages=[{"role":"user","content":prompt}])
                                    st.session_state[ai_k] = res.choices[0].message.content.strip()
                                    st.rerun()
                                except: st.error("API Error")
                        with cb:
                            if st.button("âœ… åº”ç”¨ä¿®æ”¹", key=f"app_{idx_real}", type="primary", width="stretch"):
                                push_history(f"ä¿®æ”¹ç¼–ç ä¸º: {custom_code}") # Undo
                                mask = (st.session_state.open_codes['quote'] == item['quote']) & \
                                       (st.session_state.open_codes['original_code'] == item['my_code'])
                                if mask.any():
                                    st.session_state.open_codes.loc[mask, 'aligned_code'] = custom_code
                                    st.session_state.open_codes.loc[mask, 'code'] = custom_code
                                    save_current_progress(st.session_state.open_codes)
                                    item['status'] = 'resolved'; st.success("å·²æ›´æ–°"); time.sleep(0.5); st.rerun()

                cp1, cp2 = st.columns(2)
                if st.session_state.page_num_align > 0:
                    if cp1.button("â¬…ï¸ ä¸Šä¸€é¡µ"): st.session_state.page_num_align -= 1; st.rerun()
                if start_idx + page_size < len(conflicts):
                    if cp2.button("ä¸‹ä¸€é¡µ â¡ï¸"): st.session_state.page_num_align += 1; st.rerun()
            else:
                st.success("ğŸ‰ æ‰€æœ‰åˆ†æ­§å·²è§£å†³ï¼")
        except Exception as e: st.error(f"Error: {e}")
    
    st.divider()
    if st.button("ğŸ’¾ æ‰‹åŠ¨ä¿å­˜å¯¹é½è¿›åº¦", key="save_align_manual", width="stretch"):
         fn = save_current_progress(st.session_state.open_codes)
         st.success(f"å·²ä¿å­˜")

# -----------------------------------------------------------------------
# TAB 2: åŒä¹‰åˆå¹¶
# -----------------------------------------------------------------------
with tab_clean:
    c1, c2 = st.columns([2, 1])
    c1.markdown("#### ğŸ§¹ æ ‡ç­¾æ ‡å‡†åŒ–"); c1.caption("åˆå¹¶è¯­ä¹‰é‡å¤çš„æ ‡ç­¾ã€‚æ­¤æ“ä½œä»…æ›´æ–°ã€æœ€ç»ˆæ¸…æ´—ç¼–ç ã€‘åˆ—ã€‚")
    merge_threshold = c2.slider("ç›¸ä¼¼åº¦é˜ˆå€¼", 0.7, 0.99, 0.85)
    
    if c2.button("ğŸš€ æ‰«æé‡å¤", type="primary"):
        if not api_ready: st.error("éœ€ API Key")
        else:
            with st.spinner("åˆ†æä¸­..."):
                u_codes = df['code'].dropna().unique().tolist()
                embs = get_embeddings_dashscope(u_codes, st.session_state.api_key)
                if len(embs)>0:
                    st.session_state.merge_groups = find_synonym_groups(u_codes, embs, merge_threshold)
                    st.rerun()

    if 'merge_groups' in st.session_state and st.session_state.merge_groups:
        groups = st.session_state.merge_groups
        sorted_groups = sorted(groups.items(), key=lambda x: x[1]['score'], reverse=True)
        
        for gid, data in sorted_groups:
            codes = data["codes"]
            with st.container(border=True):
                col_info, col_act = st.columns([3, 1])
                with col_info:
                    st.write(f"**å»ºè®®ç»„** (ç›¸ä¼¼åº¦ {data['score']:.2f})")
                    all_codes_options = sorted(list(set(df['code'].dropna().unique().tolist() + codes)))
                    keep = st.multiselect("åŒ…å«æ ‡ç­¾", all_codes_options, default=codes, key=f"ms_{gid}")
                    if keep:
                        with st.expander("ğŸ“„ æŸ¥çœ‹å¼•æ–‡", expanded=True):
                            filtered_df = df[df['code'].isin(keep)][['code', 'quote']]
                            n_sample = min(5, len(filtered_df))
                            if n_sample > 0:
                                sub = filtered_df.sample(n_sample)
                                st.dataframe(sub, width="stretch", hide_index=True)
                with col_act:
                    freqs = df[df['code'].isin(keep)]['code'].value_counts()
                    rec_name = freqs.idxmax() if not freqs.empty else ""
                    new_n = st.text_input("åˆå¹¶ä¸º", value=rec_name, key=f"nn_{gid}")
                    if st.button("âœ… åˆå¹¶", key=f"bm_{gid}"):
                        push_history(f"åˆå¹¶æ ‡ç­¾: {keep} -> {new_n}") # Undo
                        st.session_state.open_codes['code'] = st.session_state.open_codes['code'].replace(keep, new_n)
                        save_current_progress(st.session_state.open_codes)
                        del st.session_state.merge_groups[gid]
                        st.success("å·²åˆå¹¶"); time.sleep(0.5); st.rerun()
        if not sorted_groups: st.success("æš‚æ— å»ºè®®")
        
    st.divider()
    if st.button("ğŸ’¾ æ‰‹åŠ¨ä¿å­˜æ¸…æ´—è¿›åº¦", key="save_clean_manual", width="stretch"):
         fn = save_current_progress(st.session_state.open_codes)
         st.success(f"å·²ä¿å­˜")

# -----------------------------------------------------------------------
# TAB 3: ç§¯æœ¨å½’ç±»
# -----------------------------------------------------------------------
with tab_kanban:
    if not HAS_SORTABLE: st.error("éœ€å®‰è£… streamlit-sortables")
    else:
        st.markdown("""<div class="custom-card-hint">ğŸ§± <b>è½´å¿ƒç¼–ç å·¥ä½œå°</b></div>""", unsafe_allow_html=True)
        cv1, cv2 = st.columns(2)
        with cv1: st.html(generate_html_tag_cloud(df))
        with cv2:
            top = df['code'].value_counts().head(10).reset_index()
            top.columns = ['code', 'count']
            c = alt.Chart(top).mark_bar().encode(
                x='count', y=alt.Y('code', sort='-x'), tooltip=['code','count']
            ).properties(height=200)
            st.altair_chart(c, width="stretch")

        st.divider()
        if st.session_state.clusters_cache is None:
            if st.button("ğŸ”„ åˆå§‹åŒ–/é‡ç½® ç§¯æœ¨å †"):
                if not api_ready: st.error("éœ€ API Key")
                else:
                    with st.spinner("èšç±»ä¸­..."):
                        uc = df['code'].dropna().unique().tolist()
                        embs = get_embeddings_dashscope(uc, st.session_state.api_key)
                        if len(embs)>0:
                            cl = perform_clustering(uc, embs, distance_threshold=0.4)
                            k_data = []
                            leftover = []
                            for lbl, items in cl.items():
                                freqs = {c: len(df[df['code']==c]) for c in items}
                                items_freq = [f"{c} (x{freqs[c]})" for c in items]
                                if len(items)>=2:
                                    rep = max(freqs, key=freqs.get)
                                    k_data.append({'header': f"{rep}", 'items': items_freq})
                                else: leftover.extend(items_freq)
                            k_data.insert(0, {'header': 'â“ å¾…å®šåŒº', 'items': leftover})
                            k_data.append({'header': 'ğŸ—‘ï¸ å›æ”¶ç«™', 'items': []})
                            st.session_state.sortable_items = k_data
                            st.session_state.clusters_cache = True
                            st.rerun()
        
        if 'sortable_items' in st.session_state:
            with st.expander("ğŸ”§ ç»´åº¦ç®¡ç†", expanded=True):
                c_m1, c_m2 = st.columns([2, 1])
                headers = [g['header'] for g in st.session_state.sortable_items]
                with c_m1:
                    edit_df = pd.DataFrame(headers, columns=["åˆ†ç±»åç§°"])
                    edited_df = st.data_editor(edit_df, width="stretch", hide_index=True, key="hed")
                    if st.button("âœ… åº”ç”¨åç§°ä¿®æ”¹", width="stretch"):
                        push_history("ä¿®æ”¹åˆ†ç±»åç§°") # Undo
                        new_h = edited_df["åˆ†ç±»åç§°"].tolist()
                        if len(new_h) == len(set(new_h)):
                            new_state = []
                            old_map = {g['header']: g['items'] for g in st.session_state.sortable_items}
                            for h in new_h:
                                new_state.append({'header': h, 'items': old_map.get(h, [])})
                            for old_h, old_i in old_map.items():
                                if old_h not in new_h and old_i: new_state[0]['items'].extend(old_i)
                            st.session_state.sortable_items = new_state
                            st.rerun()
                with c_m2:
                    new_dim = st.text_input("æ–°å»ºç»´åº¦")
                    if st.button("â• æ·»åŠ ", width="stretch"):
                        if new_dim and new_dim not in headers:
                            push_history(f"æ·»åŠ åˆ†ç±»: {new_dim}") # Undo
                            st.session_state.sortable_items.insert(1, {'header': new_dim, 'items': []})
                            st.rerun()

            view_opts = st.multiselect("æ˜¾ç¤ºç»´åº¦", headers, default=headers[:6])
            curr_view = [g for g in st.session_state.sortable_items if g['header'] in view_opts]
            res = sort_items(curr_view, multi_containers=True, direction='vertical', key="kb")
            
            if res != curr_view:
                push_history("æ‹–æ‹½ç§¯æœ¨åˆ†ç±»") # Undo
                res_map = {g['header']: g['items'] for g in res}
                new_full_state = []
                for g in st.session_state.sortable_items:
                    if g['header'] in res_map: g['items'] = res_map[g['header']]
                    new_full_state.append(g)
                st.session_state.sortable_items = new_full_state
                st.rerun()

            if st.button("ğŸ’¾ ä¿å­˜å½’ç±»ç»“æœ (è‡³ Page 3)", type="primary", width="stretch"):
                push_history("ä¿å­˜è½´å¿ƒå½’ç±»") # Undo
                new_recs = []
                for g in st.session_state.sortable_items:
                    cat = g['header']
                    if 'å›æ”¶' in cat or 'å¾…å®š' in cat: continue
                    for it in g['items']:
                        code = it.split(' (x')[0]
                        new_recs.append({
                            'code': code, 'category': cat, 'confidence': 5, 
                            'reasoning': 'äººå·¥æ‹–æ‹½', 'status': 'Accepted'
                        })
                if new_recs:
                    ndf = pd.DataFrame(new_recs)
                    st.session_state.axial_codes_df = pd.concat([
                        st.session_state.axial_codes_df[~st.session_state.axial_codes_df['code'].isin(ndf['code'])],
                        ndf
                    ], ignore_index=True)
                    st.success(f"å·²ä¿å­˜ {len(new_recs)} æ¡ç»“æœï¼")

# =======================================================================
# 5. å…¨é‡æ¸…æ´—æ¸…å• (åŒ…å«æ‰€æœ‰ç‰ˆæœ¬)
# =======================================================================
st.divider()
st.subheader("5ï¸âƒ£ å¼€æ”¾ç¼–ç æ¸…æ´—æ¸…å• (Full Traceability)")
st.caption("å…¨æµç¨‹è¿½æº¯ï¼šåŸå§‹ -> å¯¹é½å -> æœ€ç»ˆæ¸…æ´—ã€‚æ‚¨å¯ä»¥ç›´æ¥åœ¨æ­¤è¡¨æ ¼ä¿®æ”¹ã€æœ€ç»ˆæ¸…æ´—ç¼–ç ã€‘ã€‚")

if not st.session_state.open_codes.empty:
    display_df = st.session_state.open_codes.copy()
    
    col_config = {
        "quote": st.column_config.TextColumn("åŸå§‹å¼•æ–‡", disabled=True, width="medium"),
        "original_code": st.column_config.TextColumn("ğŸ‘¤ æˆ‘çš„åŸå§‹", disabled=True),
        "peer_code": st.column_config.TextColumn("ğŸ‘¥ é˜Ÿå‹åŸå§‹", disabled=True),
        "aligned_code": st.column_config.TextColumn("ğŸ¤ å¯¹é½å (Tab1)", disabled=True),
        "code": st.column_config.TextColumn("âœ… æœ€ç»ˆæ¸…æ´— (Tab2)", disabled=False)
    }
    
    final_cols = ['quote', 'original_code', 'peer_code', 'aligned_code', 'code']
    final_cols = [c for c in final_cols if c in display_df.columns]
    
    edited_clean_df = st.data_editor(
        display_df[final_cols], 
        column_config=col_config,
        use_container_width=True,
        key="clean_editor"
    )
    
    if st.button("ğŸ’¾ ä¿å­˜æ¸…å•ä¿®æ”¹", type="primary", key="save_list_edit"):
        push_history("ä¿®æ”¹æ¸…æ´—æ¸…å•") # Undo
        st.session_state.open_codes['code'] = edited_clean_df['code']
        fn = save_current_progress(st.session_state.open_codes)
        st.success(f"ä¿®æ”¹å·²ä¿å­˜ï¼")
        time.sleep(0.5)
        st.rerun()

# =======================================================================
# 6. ç»“æœå±•ç¤º (è½´å¿ƒç¼–ç )
# =======================================================================
st.divider()
st.subheader("6ï¸âƒ£ å·²ç¡®è®¤çš„è½´å¿ƒç¼–ç ")
if not st.session_state.axial_codes_df.empty:
    st.dataframe(st.session_state.axial_codes_df[['category', 'code']], width="stretch")
