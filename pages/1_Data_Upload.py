# pages/1_Data_Upload.py (FIXED FOR EXCEL PROVENANCE)
import streamlit as st
import pandas as pd
import docx 
import re
import os
import datetime

# =======================================================================
# è¾…åŠ©å‡½æ•°ï¼šæ™ºèƒ½åˆ†å—è¯»å– (ä¿æŒä¸å˜)
# =======================================================================
CHUNK_SIZE = 800 

def ensure_save_dir():
    if not os.path.exists(SAVE_DIR):
        os.makedirs(SAVE_DIR)

def ensure_save_dir():
    if not os.path.exists(SAVE_DIR):
        os.makedirs(SAVE_DIR)

def auto_save_data(df, prefix="Processed"):
    """è‡ªåŠ¨ä¿å­˜å¤„ç†åçš„æ•°æ®"""
    ensure_save_dir()
    timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"{prefix}_{timestamp}.xlsx"
    filepath = os.path.join(SAVE_DIR, filename)
    try:
        df.to_excel(filepath, index=False)
        return filepath
    except Exception as e:
        st.error(f"è‡ªåŠ¨ä¿å­˜å¤±è´¥: {e}")
        return None

def clean_content_smart(text, matched_keyword=None):
    """ æ™ºèƒ½æ¸…æ´— (ä»…å»é™¤æ ¼å¼å™ªéŸ³ï¼Œä¸åˆ å†…å®¹) """
    if not isinstance(text, str) or not text: return ""
    
    # 1. åˆ‡æ‰æ˜¾æ€§å…³é”®è¯
    if matched_keyword and text.startswith(matched_keyword):
        text = text[len(matched_keyword):]
    
    # 2. å»é™¤ç±»ä¼¼ (00:00): çš„æ—¶é—´æˆ³
    text = re.sub(r"^.{0,15}?[\[\(ï¼ˆ]?\d{1,2}:\d{1,2}(:\d{1,2})?.*?[\]\)ï¼‰]?\s*[:ï¼š]?", "", text)
    
    # 3. å…œåº•å»é™¤å¼€å¤´çš„å†’å·
    if not matched_keyword:
        text = re.sub(r"^[^0-9\n]{1,10}?[:ï¼š]", "", text)

    return text.strip().strip(":ï¼š")

def split_sentences(text):
    if not isinstance(text, str) or not text: return []
    pattern = r"([ã€‚ï¼ï¼Ÿ!?]|\.\.\.+[â€\"']?)"
    chunks = re.split(pattern, text)
    sentences = []
    current = ""
    for chunk in chunks:
        current += chunk
        if re.match(pattern, chunk):
            sentences.append(current.strip())
            current = ""
    if current.strip(): sentences.append(current.strip())
    return [s for s in sentences if s]

# --- Excel è§£æé€»è¾‘ ---
def parse_excel_file(file):
    """
    æ™ºèƒ½è§£æ Excel
    1. å¯»æ‰¾ ID åˆ—
    2. å¯»æ‰¾ å†…å®¹ åˆ—
    3. é»˜è®¤è§’è‰²è®¾ä¸º A (å—è®¿è€…)
    """
    try:
        df = pd.read_excel(file)
    except Exception as e:
        st.error(f"Excel è¯»å–å¤±è´¥: {e}")
        return []

    # 1. æ™ºèƒ½çŒœæµ‹ ID åˆ—
    possible_id_names = ['è¢«è¯•ç¼–å·', 'è¢«è¯•ID', 'ç¼–å·', 'Participant_ID', 'Participant', 'ID', 'Subject', 'Name']
    id_col = None
    for col in df.columns:
        if any(name.lower() in str(col).lower() for name in possible_id_names):
            id_col = col
            break
    
    # 2. æ™ºèƒ½çŒœæµ‹ å†…å®¹ åˆ— (æ’é™¤IDåˆ—åï¼Œæ‰¾æœ€é•¿çš„å­—ç¬¦åˆ—ï¼Œæˆ–è€…å« Content/Text çš„åˆ—)
    content_col = None
    possible_content_names = ['content', 'text', 'å†…å®¹', 'æ–‡æœ¬', 'å›ç­”', 'Answer', 'Response']
    
    # A. ä¼˜å…ˆæ‰¾åå­—åŒ¹é…çš„
    for col in df.columns:
        if col == id_col: continue
        if any(name.lower() in str(col).lower() for name in possible_content_names):
            content_col = col
            break
    
    # B. æ²¡æ‰¾åˆ°åå­—ï¼Œæ‰¾ç¬¬ä¸€åˆ—éIDçš„åˆ—
    if not content_col:
        remaining_cols = [c for c in df.columns if c != id_col]
        if remaining_cols:
            content_col = remaining_cols[0]

    if not id_col or not content_col:
        st.warning(f"âš ï¸ æ–‡ä»¶ `{file.name}` ç»“æ„è¯†åˆ«å­˜ç–‘ã€‚\nè‡ªåŠ¨è¯†åˆ« IDåˆ—: `{id_col}` | å†…å®¹åˆ—: `{content_col}`ã€‚\nå»ºè®®è¡¨å¤´åŒ…å«ï¼š'è¢«è¯•ç¼–å·' å’Œ 'å†…å®¹'ã€‚")
        if not content_col: return []

    # 3. è½¬æ¢æ ¼å¼
    parsed_data = []
    for idx, row in df.iterrows():
        raw_text = str(row[content_col])
        # Excel æ•°æ®é€šå¸¸æ¯”è¾ƒçŸ­ï¼Œå¯èƒ½ä¸éœ€è¦åˆ‡åˆ†å¥å­ï¼Œä½†ä¸ºäº†ç»Ÿä¸€ï¼Œè¿˜æ˜¯è¿‡ä¸€éåˆ†å¥
        sents = split_sentences(raw_text)
        
        # ID æ„é€ 
        user_id = str(row[id_col]) if id_col else f"Row{idx+1}"
        
        for s in sents:
            parsed_data.append({
                "global_id": f"A-{user_id}-{idx+1}", # æ„é€ å”¯ä¸€ID
                "role_code": "A", # é»˜è®¤ä¸ºå—è®¿è€…
                "content": s,
                "source_file": file.name,
                "file_index": 999 # Excel é»˜è®¤æ”¾æœ€å
            })
            
    return parsed_data

# --- Word/Txt è§£æé€»è¾‘ (ä¿ç•™åŸé€»è¾‘) ---
def parse_lines_optimized(lines, q_list, a_list, force_non_q_to_a=False):
    parsed = []
    current_role = "N"
    q_list = sorted([str(k).strip() for k in q_list if str(k).strip()], key=len, reverse=True)
    a_list = sorted([str(k).strip() for k in a_list if str(k).strip()], key=len, reverse=True)
    
    for line in lines:
        line = line.strip()
        if not line: continue
        line = line.replace('\ufeff', '')
        
        detected_role = None
        content = line
        matched_kw = None
        
        for kw in q_list:
            if line.startswith(kw):
                detected_role = "Q"; matched_kw = kw; break
        
        if not detected_role:
            for kw in a_list:
                if line.startswith(kw):
                    detected_role = "A"; matched_kw = kw; break
            if not detected_role and force_non_q_to_a:
                detected_role = "A"; matched_kw = None 
        
        if detected_role:
            content = clean_content_smart(line, matched_kw)
            current_role = detected_role
        else:
            if current_role != "N": content = line 
            else: current_role = "A"; content = clean_content_smart(line, None)

        sents = split_sentences(content)
        for s in sents:
            parsed.append({"role": current_role, "content": s})
    return parsed

def read_txt_docx(file):
    lines = []
    try:
        if file.name.endswith('.docx'):
            doc = docx.Document(file)
            for para in doc.paragraphs:
                if para.text.strip(): lines.append(para.text.strip())
        elif file.name.endswith('.txt'):
            content = file.getvalue().decode("utf-8")
            lines = content.splitlines()
    except Exception as e:
        st.error(f"è¯»å–å¤±è´¥: {e}")
    return lines

# =======================================================================
# 1. é¡µé¢é…ç½®
# =======================================================================
st.set_page_config(page_title="æ•°æ®é¢„å¤„ç†", layout="wide")
st.markdown("""
<style>
    .stApp { font-family: "Microsoft YaHei", sans-serif; }
    div[data-testid="stCheckbox"] label span p { font-size: 18px !important; font-weight: bold; color: #d63031; }
    .big-caption { font-size: 16px !important; color: #666; margin-bottom: 10px; }
</style>
""", unsafe_allow_html=True)

st.title("åŒºåŸŸ1: æ•°æ®å¯¼å…¥ä¸é¢„å¤„ç†ä¸­å¿ƒ ğŸ“¥")

# Session State
if 'atomic_df' not in st.session_state: st.session_state.atomic_df = None
if 'processed_df' not in st.session_state: st.session_state.processed_df = None
if 'q_keywords' not in st.session_state: st.session_state.q_keywords = ["è®¿è°ˆè€…", "ä¸»æŒäºº", "Q"]
if 'a_keywords' not in st.session_state: st.session_state.a_keywords = ["å—è®¿è€…", "A"]

# =======================================================================
# æ­¥éª¤ 1: å¯¼å…¥è®¾ç½® (é’ˆå¯¹éExcelæ•°æ®)
# =======================================================================
with st.container(border=True):
    st.subheader("ğŸ› ï¸ æ­¥éª¤ 1: è§£æè§„åˆ™é…ç½® (ä»…é’ˆå¯¹ Word/Txt)")
    
    col1, col2 = st.columns(2)
    def tag_manager(label, key_prefix, s_list):
        c_in, c_btn = col1.columns([3,1]) if key_prefix=='q' else col2.columns([3,1])
        with c_in: new = st.text_input(label, key=f"{key_prefix}_in", label_visibility="collapsed", placeholder=f"è¾“å…¥{label}...")
        with c_btn: 
            if st.button("â•", key=f"{key_prefix}_add"): 
                if new and new not in s_list: s_list.append(new); st.rerun()
        if s_list: st.caption(" | ".join(s_list))

    with col1:
        st.info("ğŸ¤ è®¿è°ˆè€… (Interviewer)")
        tag_manager("å…³é”®è¯", "q", st.session_state.q_keywords)
    with col2:
        st.success("ğŸ‘¤ å—è®¿è€… (Interviewee)")
        tag_manager("å…³é”®è¯", "a", st.session_state.a_keywords)
    
    force_mode = st.checkbox("ğŸ”˜ å¼€å¯ã€éè®¿è°ˆè€…å³å—è®¿è€…ã€‘æ¨¡å¼ (æ¨è)", value=True)

# =======================================================================
# æ­¥éª¤ 2: æ–‡ä»¶ä¸Šä¼ 
# =======================================================================
with st.container(border=True):
    st.subheader("ğŸ“‚ æ­¥éª¤ 2: æ•°æ®ä¸Šä¼ ")
    st.info("æ”¯æŒ .xlsx (è‡ªåŠ¨è¯†åˆ«IDåˆ—), .docx, .txt (è‡ªåŠ¨è§’è‰²åˆ‡åˆ†)")
    
    uploaded_files = st.file_uploader("æ‹–æ‹½æ–‡ä»¶åˆ°æ­¤å¤„", type=["xlsx", "xls", "txt", "docx"], accept_multiple_files=True)

    if uploaded_files:
        if st.button("ğŸš€ å¼€å§‹è§£æ (Parse All)", type="primary"):
            all_data = []
            progress = st.progress(0, text="æ­£åœ¨è§£æ...")
            
            for i, f in enumerate(uploaded_files):
                # A. Excel å¤„ç†åˆ†æ”¯
                if f.name.endswith(('.xlsx', '.xls')):
                    units = parse_excel_file(f)
                    all_data.extend(units)
                
                # B. Word/Txt å¤„ç†åˆ†æ”¯
                else:
                    lines = read_txt_docx(f)
                    units = parse_lines_optimized(lines, st.session_state.q_keywords, st.session_state.a_keywords, force_mode)
                    f_idx = f"{i+1:02d}"
                    for r_i, u in enumerate(units):
                        gid = f"{u['role']}-{f_idx}-{r_i+1:03d}"
                        all_data.append({
                            "global_id": gid, "role_code": u['role'], "content": u['content'],
                            "source_file": f.name, "file_index": i
                        })
                
                progress.progress((i+1)/len(uploaded_files))
            
            if all_data:
                st.session_state.atomic_df = pd.DataFrame(all_data)
                # æ¸…é™¤æ—§çš„æ»‘å—çŠ¶æ€
                keys_to_del = [k for k in st.session_state.keys() if k.startswith(("slider_", "num_s_", "num_e_"))]
                for k in keys_to_del: del st.session_state[k]
                st.session_state.processed_df = None
                
                st.success(f"è§£æå®Œæˆï¼å…±è·å– {len(all_data)} æ¡æ•°æ®ã€‚")
                st.rerun()
            else:
                st.error("æœªèƒ½è§£æå‡ºæœ‰æ•ˆæ•°æ®ã€‚å¦‚æœæ˜¯Excelï¼Œè¯·æ£€æŸ¥æ˜¯å¦åŒ…å«'è¢«è¯•ç¼–å·'è¡¨å¤´ã€‚")

# =======================================================================
# æ­¥éª¤ 3: è£å‰ªä¸ç»„å—
# =======================================================================
if st.session_state.atomic_df is not None:
    st.divider()
    st.subheader("âœ‚ï¸ æ­¥éª¤ 3: æ•°æ®è£å‰ªä¸ç»„å—")
    
    df = st.session_state.atomic_df
    
    # 1. ç‰©ç†è£å‰ª (ä»…é’ˆå¯¹ Word/Txt æ¥æºçš„æ–‡ä»¶ï¼ŒExcel é€šå¸¸ä¸éœ€è¦)
    files = df['source_file'].unique()
    non_excel_files = [f for f in files if not f.endswith(('.xlsx', '.xls'))]
    
    if non_excel_files:
        with st.expander("âœ‚ï¸ å¯¹è¯æ–‡ä»¶é¦–å°¾è£å‰ª (Word/Txt)", expanded=True):
            trimmed_dfs = []
            # å…ˆåˆ†ç¦» Excel æ•°æ®ç›´æ¥ä¿ç•™
            excel_df = df[df['source_file'].str.endswith(('.xlsx', '.xls'))]
            if not excel_df.empty: trimmed_dfs.append(excel_df)
            
            for f_name in non_excel_files:
                sub_df = df[df['source_file'] == f_name].reset_index(drop=True)
                total = len(sub_df)
                if total > 0:
                    k_s = f"num_s_{f_name}"; k_e = f"num_e_{f_name}"; k_sl = f"slider_{f_name}"
                    if k_s not in st.session_state: st.session_state[k_s]=0; st.session_state[k_e]=total; st.session_state[k_sl]=(0,total)
                    
                    def update_slide(): st.session_state[k_s], st.session_state[k_e] = st.session_state[k_sl]
                    def update_num(): 
                        s,e = st.session_state[k_s], st.session_state[k_e]
                        if s>e: s=e
                        st.session_state[k_sl] = (s,e)
                    
                    st.markdown(f"**{f_name}**")
                    c1,c2,c3 = st.columns([1,4,1])
                    with c1: st.number_input("å§‹",0,total,key=k_s,on_change=update_num,label_visibility="collapsed")
                    with c2: st.slider("",0,total,key=k_sl,on_change=update_slide,label_visibility="collapsed")
                    with c3: st.number_input("ç»ˆ",0,total,key=k_e,on_change=update_num,label_visibility="collapsed")
                    
                    s,e = st.session_state[k_sl]
                    trimmed_dfs.append(sub_df.iloc[s:e])
            
            df_trimmed = pd.concat(trimmed_dfs).reset_index(drop=True)
    else:
        df_trimmed = df # å…¨æ˜¯ Excelï¼Œæ— éœ€è£å‰ª

    # 2. ç»„å—è®¾ç½®
    st.markdown("#### ğŸ“¦ æ™ºèƒ½ç»„å— (Batching)")
    col_b1, col_b2 = st.columns([1, 3])
    with col_b1:
        batch_size = st.number_input("ç›®æ ‡å­—æ•°/ç»„å—", value=800, step=100)
    
    if st.button("âš¡ ç”Ÿæˆæœ€ç»ˆæ•°æ®å¹¶ä¿å­˜", type="primary"):
        # æ‰§è¡Œç»„å—
        batch_ids = []
        curr_id = 1; curr_len = 0
        
        for idx, row in df_trimmed.iterrows():
            l = len(str(row['content']))
            if curr_len > batch_size:
                curr_id += 1; curr_len = 0
            batch_ids.append(curr_id)
            curr_len += l
            
        df_trimmed['batch_id'] = batch_ids
        st.session_state.processed_df = df_trimmed
        
        # è‡ªåŠ¨ä¿å­˜
        saved_path = auto_save_data(df_trimmed)
        if saved_path:
            st.success(f"âœ… æ•°æ®å·²è‡ªåŠ¨å¤‡ä»½è‡³: `{saved_path}`")
        st.rerun()

# =======================================================================
# æ­¥éª¤ 4: ç»“æœä¸å¯¼å‡º
# =======================================================================
if st.session_state.processed_df is not None:
    st.divider()
    st.subheader("âœ… æ­¥éª¤ 4: å‡†å¤‡å°±ç»ª")
    
    df_final = st.session_state.processed_df
    
    # é¢œè‰²åŒºåˆ†
    def color_row(row):
        color = '#e9ecef' if row['role_code'] == 'Q' else '#d4edda'
        return [f'background-color: {color}; color: black; border-bottom: 1px solid white;'] * len(row)

    st.dataframe(
        df_final[['batch_id', 'global_id', 'role_code', 'content', 'source_file']].style.apply(color_row, axis=1),
        use_container_width=True, height=400
    )
    
    c1, c2, c3 = st.columns([1, 2, 2])
    with c1:
        if st.button("ğŸ—‘ï¸ é‡æ–°å¤„ç†"): st.session_state.processed_df = None; st.rerun()
    with c2:
        # æ‰‹åŠ¨ä¿å­˜æŒ‰é’® (å…¶å®å·²ç»è‡ªåŠ¨ä¿å­˜äº†ï¼Œä½†æä¾›ä¸€ä¸ªæ˜¾æ€§ä¸‹è½½)
        csv = df_final.to_csv(index=False).encode('utf-8-sig')
        st.download_button("ğŸ’¾ ä¸‹è½½å¤„ç†åçš„æ•°æ® (.csv)", csv, "processed_data.csv", "text/csv")
    with c3:
        st.session_state.final_coding_data = df_final
        st.button("â¡ï¸ å‰å¾€ç¼–ç  (Go to Coding)", type="primary", on_click=lambda: st.switch_page("pages/2_Open_Coding.py"))
