# pages/1_Data_Upload.py (FIXED FOR EXCEL PROVENANCE)
import streamlit as st
import pandas as pd
import io
import docx 

# =======================================================================
# è¾…åŠ©å‡½æ•°ï¼šæ™ºèƒ½åˆ†å—è¯»å– (ä¿æŒä¸å˜)
# =======================================================================
CHUNK_SIZE = 800 

def read_docx_chunked(file, chunk_size):
    doc = docx.Document(file); chunks = []; current_chunk = "";
    for para in doc.paragraphs:
        text = para.text.strip()
        if not text: continue
        if len(current_chunk) + len(text) < chunk_size:
            current_chunk += text + "\n"
        else:
            if current_chunk: chunks.append(current_chunk.strip())
            current_chunk = text + "\n"
    if current_chunk: chunks.append(current_chunk.strip())
    return pd.DataFrame(chunks, columns=["text_content"])

def read_txt_chunked(file, chunk_size):
    string_data = file.getvalue().decode("utf-8"); lines = string_data.splitlines(); chunks = []; current_chunk = "";
    for line in lines:
        text = line.strip();
        if not text: continue
        if len(current_chunk) + len(text) < chunk_size:
            current_chunk += text + "\n"
        else:
            if current_chunk: chunks.append(current_chunk.strip())
            current_chunk = text + "\n"
    if current_chunk: chunks.append(current_chunk.strip())
    return pd.DataFrame(chunks, columns=["text_content"])

# =======================================================================
# é¡µé¢é€»è¾‘
# =======================================================================
st.set_page_config(page_title="åŒºåŸŸ1: æ•°æ®ä¸Šä¼ ", layout="wide")
st.title("åŒºåŸŸ1: æ•°æ®ä¸Šä¼ ä¸åˆå¹¶ (æ™ºèƒ½åˆ†å—ç‰ˆ) ğŸ“‚")

if 'raw_data' not in st.session_state:
    st.session_state.raw_data = None

with st.container(border=True):
    st.subheader("æ­¥éª¤ 1: æ‰¹é‡ä¸Šä¼ è®¿è°ˆæ–‡ä»¶")
    st.info(f"ğŸ’¡ **TokenèŠ‚çº¦ç­–ç•¥å·²æ¿€æ´»**ï¼šWord/Txtæ–‡ä»¶ä¼šè¢«åˆå¹¶ä¸º **800å­—å·¦å³çš„å¤§å—**ã€‚\næ³¨æ„ï¼š\nè‹¥å¯¼å…¥excelï¼Œè¯·åŒ…å«'è¢«è¯•ç¼–å·', 'Participant_ID',æˆ–'ID'ä½œä¸ºè¯†åˆ«è¢«è¯•ç¼–å·çš„åˆ—\nè‹¥å¯¼å…¥å…¶ä»–æ–‡ä»¶ç±»å‹ï¼Œå°†ä»¥æ–‡ä»¶åä½œä¸ºæ–‡ä»¶æ¥æºæ ‡è®°")
    
    col_size, col_upload = st.columns([1, 3])
    with col_size:
        user_chunk_size = st.number_input("åˆå¹¶é˜ˆå€¼ (å­—ç¬¦æ•°)", min_value=100, max_value=3000, value=800, step=100)

    with col_upload:
        uploaded_files = st.file_uploader(
            "æ‹–æ‹½ä¸Šä¼ æˆ–ç‚¹å‡»é€‰æ‹© (æ”¯æŒå¤šé€‰)", 
            type=["csv", "txt", "xlsx", "docx"],
            accept_multiple_files=True
        )

if uploaded_files:
    try:
        all_dfs = []
        for uploaded_file in uploaded_files:
            file_name = uploaded_file.name
            temp_df = pd.DataFrame()
            source_column = 'source_file' # é»˜è®¤ä½¿ç”¨æ–‡ä»¶å

            if uploaded_file.type in ["text/plain", "application/vnd.openxmlformats-officedocument.wordprocessingml.document"]:
                # Word/TXT æ–‡ä»¶ä½¿ç”¨åˆ†å—é€»è¾‘
                if uploaded_file.type == "text/plain":
                    temp_df = read_txt_chunked(uploaded_file, chunk_size=user_chunk_size)
                else:
                    temp_df = read_docx_chunked(uploaded_file, chunk_size=user_chunk_size)
            
            elif uploaded_file.type in ["text/csv", "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"]:
                # CSV/Excel æ–‡ä»¶å¤„ç† (æ–°é€»è¾‘)
                if uploaded_file.type == "text/csv":
                    temp_df = pd.read_csv(uploaded_file)
                else:
                    temp_df = pd.read_excel(uploaded_file)
                
                # è¯†åˆ«è¢«è¯•ç¼–å·åˆ— (æ–°é€»è¾‘)
                id_cols = ['è¢«è¯•ç¼–å·', 'Participant_ID', 'ID']
                
                found_id_col = next((col for col in id_cols if col in temp_df.columns), None)
                if found_id_col:
                    source_column = found_id_col
                    st.caption(f"âœ… è¯†åˆ«åˆ°æº¯æºå­—æ®µ: `{source_column}`ã€‚")
                else:
                    st.caption(f"âš ï¸ æœªæ‰¾åˆ°æº¯æºå­—æ®µã€‚å°†ä½¿ç”¨æ–‡ä»¶å `{file_name}`ã€‚")
            
            # 2. æ•´åˆæ•°æ® (ç¡®ä¿æœ‰ text_content åˆ—)
            if not temp_df.empty:
                # ä¼˜å…ˆå¯»æ‰¾ text_contentï¼Œå¦‚æœ CSV/Excel æ²¡æœ‰ï¼Œåˆ™ç”¨ç¬¬ä¸€ä¸ªé ID åˆ—æ›¿ä»£
                text_col = 'text_content'
                if text_col not in temp_df.columns:
                    non_id_cols = [col for col in temp_df.columns if col not in id_cols and col != source_column]
                    if non_id_cols:
                        temp_df.rename(columns={non_id_cols[0]: text_col}, inplace=True)
                        st.caption(f"âš ï¸ è‡ªåŠ¨å°† `{non_id_cols[0]}` åˆ—è¯†åˆ«ä¸ºæ–‡æœ¬å†…å®¹ã€‚")
                    else:
                        st.warning(f"æ–‡ä»¶ {file_name} æ— æ³•è¯†åˆ«æ–‡æœ¬å†…å®¹ï¼Œå·²è·³è¿‡ã€‚")
                        continue
                
                temp_df['source_file'] = temp_df[source_column] if source_column != 'source_file' else file_name
                temp_df = temp_df[[text_col, 'source_file']].rename(columns={text_col: 'text_content'})
                all_dfs.append(temp_df)
                st.caption(f"âœ… å·²åŠ è½½: `{file_name}` -> å…± **{len(temp_df)}** æ¡æ•°æ®ã€‚")

        # 3. æœ€ç»ˆåˆå¹¶
        if all_dfs:
            final_df = pd.concat(all_dfs, ignore_index=True)
            st.divider()
            st.success(f"ğŸ‰ å¤„ç†å®Œæˆï¼å…±åˆå¹¶ä¸º **{len(final_df)}** æ¡æ•°æ®ã€‚")
            
            with st.container(border=True):
                st.subheader("åˆå¹¶åæ•°æ®é¢„è§ˆ")
                cols = ['source_file', 'text_content']
                st.dataframe(final_df[cols], height=400)
            
            st.session_state.raw_data = final_df
            st.button("ç¡®è®¤æ— è¯¯ï¼Œå‰å¾€æ­¥éª¤2è¿›è¡Œç¼–ç ", type="primary", on_click=lambda: st.switch_page("pages/2_Open_Coding.py"))
        else:
            st.error("æœªèƒ½ä»ä¸Šä¼ çš„æ–‡ä»¶ä¸­æå–åˆ°æœ‰æ•ˆæ•°æ®ã€‚")

    except Exception as e:
        st.error(f"å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")

# (å¯é€‰) æ•°æ®æ¸…æ´—æŒ‰é’®
if st.session_state.raw_data is not None:
    with st.expander("æ•°æ®æ¸…æ´—å·¥å…·"):
        if st.button("åˆ é™¤æ‰€æœ‰ç©ºè¡Œ"):
            old_len = len(st.session_state.raw_data)
            df_cleaned = st.session_state.raw_data.dropna(subset=['text_content'])
            df_cleaned = df_cleaned[df_cleaned['text_content'].str.strip() != ""]
            new_len = len(df_cleaned)
            st.session_state.raw_data = df_cleaned.reset_index(drop=True)
            st.success(f"å·²åˆ é™¤ {old_len - new_len} æ¡ç©ºæ•°æ®ã€‚")
            st.rerun()
