import streamlit as st
import pandas as pd
import time 
from openai import OpenAI 
import json
import os 
import glob
from io import BytesIO 
import datetime

# =======================================================================
# 0. æ•°æ®æŒä¹…åŒ–ä¸æ¢å¤æ¨¡å— (Data Persistence)
# =======================================================================

RECOVERY_DIR = "recovery_opening_coding"

def ensure_recovery_dir():
    if not os.path.exists(RECOVERY_DIR):
        os.makedirs(RECOVERY_DIR)

def get_current_filename(theme):
    """
    ç”Ÿæˆæ–‡ä»¶åï¼šOpening_ä¸»é¢˜_æ—¥æœŸ.jsonl
    """
    # æ¸…æ´—æ–‡ä»¶åä¸­çš„éæ³•å­—ç¬¦
    safe_theme = "".join([c for c in theme if c.isalnum() or c in (' ', '_', '-')]).strip()
    if not safe_theme: safe_theme = "Untitled_Project"
    
    date_str = datetime.datetime.now().strftime("%Y%m%d") 
    return f"Opening_{safe_theme}_{date_str}.jsonl"

def save_record_to_jsonl(record_dict, filename):
    """
    è¿½åŠ å†™å…¥å•æ¡å¤„ç†è®°å½• (åŒ…å«è¯¥è¡Œç”Ÿæˆçš„æ‰€æœ‰ç¼–ç )
    """
    ensure_recovery_dir()
    filepath = os.path.join(RECOVERY_DIR, filename)
    
    # è¡¥å……æ—¶é—´æˆ³
    record_dict['timestamp'] = datetime.datetime.now().isoformat()
    
    try:
        with open(filepath, "a", encoding="utf-8") as f:
            f.write(json.dumps(record_dict, ensure_ascii=False) + "\n")
    except Exception as e:
        st.error(f"è‡ªåŠ¨ä¿å­˜å¤±è´¥: {e}")

def load_from_jsonl(filepath):
    """
    ä» JSONL è¯»å–æ•°æ®ï¼Œå¹¶å°†å…¶æ‰å¹³åŒ–ä¸º open_codes éœ€è¦çš„æ ¼å¼
    """
    records = []
    if os.path.exists(filepath):
        with open(filepath, "r", encoding="utf-8") as f:
            for line in f:
                try:
                    if line.strip():
                        records.append(json.loads(line))
                except:
                    continue
    
    # å°†è®°å½•è½¬æ¢ä¸º DataFrame æ‰€éœ€çš„æ‰å¹³åˆ—è¡¨
    flat_codes = []
    processed_indices = set()
    file_sources = set() # ç”¨äºæ ¡éªŒ
    
    for r in records:
        idx = r.get('original_row_index')
        if idx is not None:
            processed_indices.add(idx)
            
        # æå–è¯¥è¡Œå¯¹åº”çš„ç¼–ç åˆ—è¡¨
        codes_list = r.get('generated_codes', [])
        source_file = r.get('source_file', 'unknown')
        file_sources.add(source_file)
        
        if isinstance(codes_list, list):
            for c in codes_list:
                if isinstance(c, dict):
                    flat_codes.append({
                        'source_file': source_file,
                        'code': c.get('code'),
                        'quote': c.get('quote'),
                        'confidence': c.get('confidence', 0),
                        'original_row_index': idx
                    })
    
    return pd.DataFrame(flat_codes), processed_indices, file_sources

# =======================================================================
# 1. æ ¸å¿ƒé€»è¾‘å‡½æ•°åŒº
# =======================================================================

def call_qwen_api(api_key, model_id, prompt_text, temperature=0.1):
    try:
        if model_id in ["qwen-max", "qwen-plus", "deepseek-v3", "deepseek-r1", "kimi-k2-thinking", "glm-4.6"]:
            base_url = "https://dashscope.aliyuncs.com/compatible-mode/v1"
            client_key = api_key 
        elif model_id.startswith("gpt"):
            base_url = "https://api.openai.com/v1"
            client_key = st.session_state.get('openai_key', api_key) 
        elif model_id.startswith("gemini"):
            base_url = "https://api.gemini.com/v1" 
            client_key = st.session_state.get('gemini_key', api_key) 
        else:
            base_url = "https://dashscope.aliyuncs.com/compatible-mode/v1"
            client_key = api_key

        client = OpenAI(api_key=client_key, base_url=base_url)
        
        response = client.chat.completions.create(
            model=model_id,
            temperature=temperature,
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä½ä¸¥è°¨çš„æ‰æ ¹ç†è®ºç ”ç©¶ä¸“å®¶ï¼Œè¯·ä¸¥æ ¼éµå®ˆç”¨æˆ·æŒ‡ä»¤ã€‚"},
                {"role": "user", "content": prompt_text}
            ],
        )

        usage = response.usage
        total_tokens = getattr(usage, "total_tokens", 0)
        
        return {"success": True, "text": response.choices[0].message.content, "tokens": total_tokens}
    except Exception as e:
        return {"success": False, "error": f"API Exception: {str(e)}", "tokens": 0}

# (V51) Meta-Prompt
def create_background_meta_prompt(core_theme):
    return f"""
ä½ æ˜¯ä¸€ä½ä¸“ç²¾äºæ‰æ ¹ç†è®ºæ–¹æ³•è®ºçš„é¡¶å°–ä¸“å®¶ã€‚ç”¨æˆ·æ­£åœ¨ç ”ç©¶æ ¸å¿ƒä¸»é¢˜ï¼šâ€œ{core_theme}â€ã€‚

ä½ çš„ä»»åŠ¡æ˜¯ï¼šä¸ºåç»­çš„ç¼–ç å·¥ä½œåˆ¶å®šä¸€å¥—**æ“ä½œåŒ–åˆ¤åˆ«æ ‡å‡†**ã€‚

è¯·ä¸¥æ ¼ã€ä¸”ä»…è¾“å‡ºä»¥ä¸‹ JSON æ ¼å¼ï¼š

{{
  "definition_logic": "çº³å…¥æ ‡å‡†ï¼šè¯·ç”¨200å­—å·¦å³å®šä¹‰ï¼Œä»€ä¹ˆæ ·çš„æ–‡æœ¬æ‰ç®—å±äºè¿™ä¸ªä¸»é¢˜ï¼Ÿ",
  "exclusion_logic": "æ’é™¤æ ‡å‡†ï¼šè¯·ç”¨200å­—å·¦å³å®šä¹‰ï¼Œä»€ä¹ˆæ ·å³ä½¿æ²¾è¾¹ä½†ä¹Ÿå¿…é¡»æ’é™¤çš„å†…å®¹ï¼Ÿï¼ˆå¿…é¡»åŒ…å«å…·ä½“çš„è¾¹ç•Œæƒ…å†µæˆ–æ··æ·†æ¦‚å¿µï¼‰"
}}
"""

# (V53) Final Coding Prompt
def create_final_coding_prompt(core_theme, definition_logic, exclusion_logic, text_to_code):
    return f"""
ä½ æ˜¯ä¸¥è°¨çš„æ‰æ ¹ç†è®ºä¸“å®¶ã€‚ä»»åŠ¡æ˜¯å¯¹[å¾…å¤„ç†æ–‡æ®µ]è¿›è¡Œå¼€æ”¾æ€§ç¼–ç ã€‚

1. æ ¸å¿ƒç„¦ç‚¹
{core_theme}

2. åˆ¤åˆ«æ ‡å‡† (å¿…é¡»ä¸¥æ ¼æ‰§è¡Œ)
* çº³å…¥æ ‡å‡†:{definition_logic}
* æ’é™¤æ ‡å‡†:{exclusion_logic}

3. ç¼–ç é“å¾‹
é“å¾‹ä¸€ è¯­ä¹‰çº¯åŒ–ï¼šCodeå¿…é¡»æ˜¯è¯­ä¹‰å®Œæ•´ä¸”æœ€ç®€çŸ­çš„è¯ç»„ã€‚åˆ é™¤åŸæ–‡ä¸­ä¸åŒ…å«æ ¸å¿ƒæ„ä¹‰çš„è¯­è¨€èµ˜è¿°ï¼ˆå¦‚å£å¤´ç¦…ã€è¿æ¥è¯ã€å†—ä½™çš„ä¸»è¯­ï¼‰ã€‚
é“å¾‹äºŒ ç»†è‡´æ‹†åˆ†ï¼šä¸€æ®µè¯åŒ…å«å¤šä¸ªç‹¬ç«‹çš„åŠ¨ä½œæˆ–æ„ä¹‰ï¼Œå¿…é¡»æ‹†åˆ†æˆå¤šæ¡ã€‚ä¸¥ç¦åˆå¹¶ã€‚
é“å¾‹ä¸‰ è´´åœ°æ€§åŸåˆ™ï¼šCode å¿…é¡»æ˜¯ä½çº§ã€å…·è±¡çš„æè¿°æ€§çŸ­è¯­ï¼Œæ‹’ç»æŠ½è±¡æ¦‚å¿µã€‚
é“å¾‹å›› ç²¾å‡†å¼•ç”¨ï¼šQuote å¿…é¡»æ˜¯åŸæ–‡çš„ç²¾å‡†å¤åˆ¶ï¼Œä¸èƒ½æ”¹å†™ã€‚

4. ç¼–ç æ­¥éª¤
æ­¥éª¤1 åˆ¤åˆ«ï¼šé€å¥é˜…è¯»ï¼Œå¯¹ç…§åˆ¤åˆ«æ ‡å‡†ï¼Œè¯†åˆ«æ‰€æœ‰ç¬¦åˆçº³å…¥æ ‡å‡†çš„æ–‡æœ¬ç‰‡æ®µã€‚
æ­¥éª¤2 åˆæ¬¡åˆ‡åˆ†ï¼šå¯¹è¯†åˆ«å‡ºçš„ç‰‡æ®µæ‰§è¡ŒåŸå­åŒ–æ‹†åˆ†ï¼Œç”Ÿæˆä¸€ä¸ªåˆå§‹ä»£ç åˆ—è¡¨ã€‚
æ­¥éª¤3 ç©·å°½æ€§å®¡è®¡ï¼š
    * é‡æ–°æ ¸å¯¹ï¼šå°†ä½ ç”Ÿæˆçš„åˆå§‹ä»£ç åˆ—è¡¨ä¸[å¾…å¤„ç†æ–‡æ®µ]è¿›è¡Œå¯¹æ¯”ã€‚
    * æ£€æŸ¥é—æ¼ï¼šæ£€æŸ¥åŸå§‹æ–‡æ®µä¸­æ˜¯å¦è¿˜æœ‰ä»»ä½•ç¬¦åˆçº³å…¥æ ‡å‡†çš„ã€ä½†æœªè¢«ç¼–ç çš„å¹¶åˆ—è¯ã€è½¬æŠ˜å¥æˆ–å¯¹ç«‹æ¦‚å¿µï¼ˆä¾‹å¦‚ï¼šæ—¢è¦Aåˆè¦Bï¼‰ã€‚
    * è¡¥å……ï¼šå¦‚æœå‘ç°é—æ¼ï¼Œè¯·ç«‹å³è¡¥å……å®Œæ•´ã€‚
æ­¥éª¤4 æ¸…æ´—ï¼šå¯¹æ‰€æœ‰ä»£ç æ‰§è¡Œå‰¥ç¦»å¤–å£³ï¼Œä¿ç•™å†…æ ¸ï¼Œå¹¶è¿›è¡Œå‡€åŒ–æç‚¼ã€‚å¯¹æ¯ä¸ªæ„ä¹‰å•å…ƒï¼Œæ‰§è¡Œé“å¾‹ä¸€ï¼ˆè¯­ä¹‰çº¯åŒ–ï¼‰å’Œé“å¾‹ä¸‰ï¼ˆè´´åœ°æ€§åŸåˆ™ï¼‰ï¼Œç”Ÿæˆæœ€ç»ˆ Codeã€‚
æ­¥éª¤5 æ ¼å¼åŒ–ï¼šç”ŸæˆJSONã€‚
æ­¥éª¤6 è¿›è¡Œç½®ä¿¡åº¦confidenceè¯„åˆ†ï¼šè¿›è¡Œäº”ç‚¹è¯„åˆ†ï¼Œ1åˆ†ä¸ºéå¸¸ä¸ç¡®å®šï¼Œ2åˆ†ä¸ºæ¯”è¾ƒç¡®å®šï¼Œ3åˆ†ä¸ºæœ‰ç‚¹ç¡®å®šï¼Œ4åˆ†ä¸ºæ¯”è¾ƒç¡®å®šï¼Œ5åˆ†ä¸ºéå¸¸ç¡®å®šã€‚

5. è¾“å‡ºæ ¼å¼
åªè¾“å‡ºä¸€ä¸ªJSONæ•°ç»„ï¼Œæ¯ä¸ªå¯¹è±¡å¿…é¡»åŒ…å« code ã€quoteå’Œconfidenceã€‚
å¤šæ¡ç¼–ç ç¤ºä¾‹:
[
  {{
    "code": "(ç¬¬ä¸€ä¸ªç¼–ç æ ‡ç­¾)",
    "quote": "(æ”¯æ’‘ç¼–ç 1çš„åŸæ–‡ç‰‡æ®µ)",
    "confidence": 5
  }},
  {{
    "code": "(ç¬¬äºŒä¸ªç¼–ç æ ‡ç­¾)",
    "quote": "(æ”¯æ’‘ç¼–ç 2çš„åŸæ–‡ç‰‡æ®µ)",
    "confidence": 4
  }}
]
é›¶æ¡ç¼–ç ç¤ºä¾‹: []

[å¾…å¤„ç†æ–‡æ®µ]:
{text_to_code}

æé†’ï¼šä¸¥æ ¼éµå®ˆåˆ¤åˆ«æ ‡å‡†ä¸ç¼–ç æ­¥éª¤ï¼ŒæŒ‰ç…§è§„å®šJSONæ ¼å¼è¾“å‡ºï¼ä¸è¾“å‡ºå…¶ä»–å†…å®¹ï¼
"""

def extract_json(text, start_char='[', end_char=']'):
    try:
        if start_char == '[': start_index = text.find('[')
        else: start_index = text.find('{')
        if end_char == ']': end_index = text.rfind(']')
        else: end_index = text.rfind('}')
        if start_index != -1 and end_index != -1 and end_index > start_index:
            json_str = text[start_index : end_index + 1]
            return json.loads(json_str)
        else: return None
    except Exception as e:
        return f"JSONè§£æé”™è¯¯: {e}. åŸå§‹æ–‡æœ¬: {text}"

@st.cache_data 
def to_excel(df_raw, df_codes, df_meta):
    output = BytesIO()
    if df_raw is None: df_raw = pd.DataFrame()
    if df_codes is None: df_codes = pd.DataFrame()
    if df_meta is None: df_meta = pd.DataFrame()
    
    with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
        df_raw.to_excel(writer, index=False, sheet_name='raw_data')
        df_codes.to_excel(writer, index=False, sheet_name='open_codes')
        df_meta.to_excel(writer, index=False, sheet_name='project_meta')
    processed_data = output.getvalue()
    return processed_data

def get_manual_prompt_template():
    return f"""
ä½ æ˜¯ä¸¥è°¨çš„æ‰æ ¹ç†è®ºä¸“å®¶ã€‚ä»»åŠ¡æ˜¯å¯¹[å¾…å¤„ç†æ–‡æ®µ]è¿›è¡Œå¼€æ”¾æ€§ç¼–ç ã€‚

1. æ ¸å¿ƒç„¦ç‚¹
[è¯·åœ¨æ­¤å¤„è¾“å…¥æ ¸å¿ƒç„¦ç‚¹ç ”ç©¶ä¸»é¢˜]

2. åˆ¤åˆ«æ ‡å‡† (å¿…é¡»ä¸¥æ ¼æ‰§è¡Œ)
* çº³å…¥æ ‡å‡†:[è¯·åœ¨æ­¤å¤„ç²˜è´´çº³å…¥æ ‡å‡†]
* æ’é™¤æ ‡å‡†:[è¯·åœ¨æ­¤å¤„ç²˜è´´æ’é™¤æ’é™¤æ ‡å‡†]

3. ç¼–ç é“å¾‹
é“å¾‹ä¸€ è¯­ä¹‰çº¯åŒ–ï¼šCodeå¿…é¡»æ˜¯è¯­ä¹‰å®Œæ•´ä¸”æœ€ç®€çŸ­çš„è¯ç»„ã€‚ä»…åˆ é™¤åŸæ–‡ä¸­ä¸åŒ…å«æ ¸å¿ƒæ„ä¹‰çš„è¯­è¨€èµ˜è¿°ï¼ˆå¦‚å£å¤´ç¦…ã€è¿æ¥è¯ã€å†—ä½™çš„ä¸»è¯­ï¼‰ã€‚å½“â€œæ„å›¾â€æ˜¯ä¸»é¢˜çš„æ ¸å¿ƒæ—¶ï¼Œä¿ç•™æ„å›¾è¯ã€‚
é“å¾‹äºŒ ç»†è‡´æ‹†åˆ†ï¼šä¸€æ®µè¯åŒ…å«å¤šä¸ªç‹¬ç«‹çš„åŠ¨ä½œæˆ–æ„ä¹‰ï¼Œå¿…é¡»æ‹†åˆ†æˆå¤šæ¡ã€‚ä¸¥ç¦åˆå¹¶ã€‚
é“å¾‹ä¸‰ è´´åœ°æ€§åŸåˆ™ï¼šCode å¿…é¡»æ˜¯ä½çº§ã€å…·è±¡çš„æè¿°æ€§çŸ­è¯­ï¼Œæ‹’ç»æŠ½è±¡æ¦‚å¿µã€‚
é“å¾‹å›› ç²¾å‡†å¼•ç”¨ï¼šQuote å¿…é¡»æ˜¯åŸæ–‡çš„ç²¾å‡†å¤åˆ¶ï¼Œä¸èƒ½æ”¹å†™ã€‚

4. ç¼–ç æ­¥éª¤
æ­¥éª¤1 åˆ¤åˆ«ï¼šé€å¥é˜…è¯»ï¼Œå¯¹ç…§åŠ¨æ€åˆ¤åˆ«æ ‡å‡†ï¼Œè¯†åˆ«æ‰€æœ‰ç¬¦åˆçº³å…¥æ ‡å‡†çš„æ–‡æœ¬ç‰‡æ®µã€‚
æ­¥éª¤2 åˆæ¬¡åˆ‡åˆ†ï¼šå¯¹è¯†åˆ«å‡ºçš„ç‰‡æ®µæ‰§è¡ŒåŸå­åŒ–æ‹†åˆ†ï¼Œç”Ÿæˆä¸€ä¸ªåˆå§‹ä»£ç åˆ—è¡¨ã€‚
æ­¥éª¤3 ç©·å°½æ€§å®¡è®¡ï¼šæ£€æŸ¥é—æ¼çš„å¹¶åˆ—è¯æˆ–è½¬æŠ˜å¥ï¼Œå¹¶è¡¥å……ã€‚
æ­¥éª¤4 æ¸…æ´—ï¼šå¯¹æ‰€æœ‰ä»£ç æ‰§è¡Œå‰¥ç¦»å¤–å£³ï¼Œä¿ç•™å†…æ ¸ï¼Œå¹¶è¿›è¡Œå‡€åŒ–æç‚¼ã€‚å¯¹æ¯ä¸ªæ„ä¹‰å•å…ƒï¼Œæ‰§è¡Œè¯­ä¹‰çº¯åŒ–å’Œè´´åœ°æ€§åŸåˆ™ï¼Œç”Ÿæˆæœ€ç»ˆ Codeã€‚
æ­¥éª¤5 æ ¼å¼åŒ–ï¼šç”ŸæˆJSONã€‚
æ­¥éª¤6 è¿›è¡Œç½®ä¿¡åº¦confidenceè¯„åˆ†ï¼šè¿›è¡Œäº”ç‚¹è¯„åˆ†ã€‚

5. è¾“å‡ºæ ¼å¼
åªè¾“å‡ºä¸€ä¸ªJSONæ•°ç»„ï¼Œæ¯ä¸ªå¯¹è±¡å¿…é¡»åŒ…å« code ã€quoteå’Œconfidenceã€‚
[å¾…å¤„ç†æ–‡æ®µ]:
{{text_to_code}}

æé†’ï¼šä¸¥æ ¼éµå®ˆåˆ¤åˆ«æ ‡å‡†ä¸ç¼–ç æ­¥éª¤ï¼ŒæŒ‰ç…§è§„å®šJSONæ ¼å¼è¾“å‡ºï¼ä¸è¾“å‡ºå…¶ä»–å†…å®¹ï¼
"""


# =======================================================================
# 2. Streamlit é¡µé¢å¸ƒå±€
# =======================================================================

# åˆå§‹åŒ– Session State
if 'prompt_mode' not in st.session_state: st.session_state.prompt_mode = "1. æ™ºèƒ½å‘å¯¼ (å…¨è‡ªåŠ¨)" 
if 'custom_prompt' not in st.session_state: st.session_state.custom_prompt = get_manual_prompt_template()
if 'definition_logic' not in st.session_state: st.session_state.definition_logic = ""
if 'exclusion_logic' not in st.session_state: st.session_state.exclusion_logic = ""
if 'open_codes' not in st.session_state: st.session_state.open_codes = pd.DataFrame(columns=['source_file', 'code', 'quote', 'confidence', 'original_row_index'])
if 'core_theme' not in st.session_state: st.session_state.core_theme = "ï¼ˆè¯·åœ¨æ­¤è¾“å…¥æ‚¨çš„ç ”ç©¶ä¸»é¢˜ï¼‰" 
if 'selected_model' not in st.session_state: st.session_state.selected_model = "qwen-plus"
if 'openai_key' not in st.session_state: st.session_state.openai_key = "" 
if 'gemini_key' not in st.session_state: st.session_state.gemini_key = "" 
if 'stop_requested' not in st.session_state: st.session_state.stop_requested = False
if 'is_processing' not in st.session_state: st.session_state.is_processing = False
if 'temperature' not in st.session_state: st.session_state.temperature = 0.1
if 'total_token_usage' not in st.session_state: st.session_state.total_token_usage = 0

st.set_page_config(page_title="åŒºåŸŸ2: å¼€æ”¾æ€§ç¼–ç ", layout="wide")

# è·å–å½“å‰åŸå§‹æ•°æ® (ç”¨äºæ ¡éªŒ)
df = st.session_state.raw_data if 'raw_data' in st.session_state and st.session_state.raw_data is not None else None

# [NEW] ä¾§è¾¹æ ï¼šå†å²å­˜æ¡£æ¢å¤ (ä¸è½´å¿ƒç¼–ç ä¸€è‡´çš„é€»è¾‘)
with st.sidebar:
    st.header("ğŸ“‚ è¿›åº¦ç®¡ç†")
    st.warning("âš ï¸ æ³¨æ„ï¼šä¸ºäº†ä¿è¯æ–­ç‚¹ç»­ä¼ çš„å‡†ç¡®æ€§ï¼Œè¯·å‹¿åœ¨ç ”ç©¶è¿‡ç¨‹ä¸­éšæ„ä¿®æ”¹ä¸Šä¼ æ–‡ä»¶çš„æ–‡ä»¶åæˆ–è¡Œé¡ºåºã€‚")
    st.info("ç³»ç»Ÿä¼šè‡ªåŠ¨å°†ç¼–ç ç»“æœä¿å­˜åˆ° `recovery_opening_coding` æ–‡ä»¶å¤¹ã€‚")
    
    ensure_recovery_dir()
    # æ‰«æ jsonl æ–‡ä»¶ï¼ŒæŒ‰æ—¶é—´å€’åº
    jsonl_files = glob.glob(os.path.join(RECOVERY_DIR, "*.jsonl"))
    jsonl_files.sort(key=os.path.getmtime, reverse=True)
    
    if jsonl_files:
        st.subheader("ğŸ“¥ æ¢å¤è¿›åº¦")
        selected_file = st.selectbox("é€‰æ‹©å†å²æ–‡ä»¶", [os.path.basename(f) for f in jsonl_files], index=0)
        
        if st.button("ğŸ”„ è½½å…¥é€‰ä¸­æ–‡ä»¶"):
            filepath = os.path.join(RECOVERY_DIR, selected_file)
            loaded_df, processed_indices, file_sources = load_from_jsonl(filepath)
            
            if not loaded_df.empty:
                # [NEW] æ•°æ®æºæ ¡éªŒ
                if df is not None and 'source_file' in df.columns:
                    current_files = set(df['source_file'].unique())
                    if not file_sources.issubset(current_files):
                        st.warning(f"âš ï¸ è­¦å‘Šï¼šå­˜æ¡£ä¸­çš„æºæ–‡ä»¶ ({file_sources}) ä¸å½“å‰ä¸Šä¼ çš„æ–‡ä»¶ ({current_files}) ä¸å®Œå…¨åŒ¹é…ã€‚è¿™å¯èƒ½å¯¼è‡´è¡Œç´¢å¼•é”™ä½ã€‚")
                
                # 1. è½½å…¥åˆ° session_state (å…¨é‡è¦†ç›–)
                st.session_state.open_codes = loaded_df
                
                # [NEW] è¿›åº¦æ˜¾ç¤º
                total_rows = len(df) if df is not None else "Unknown"
                processed_count = len(processed_indices)
                st.success(f"âœ… æˆåŠŸæ¢å¤ {len(loaded_df)} æ¡ç¼–ç è®°å½•ï¼")
                st.info(f"ğŸ“Š è¿›åº¦çŠ¶æ€: å·²å¤„ç† {processed_count} / {total_rows} è¡Œ")
                
                time.sleep(1)
                st.rerun()
            else:
                st.warning("è¯¥æ–‡ä»¶ä¸ºç©ºæˆ–æ ¼å¼ä¸åŒ…å«æœ‰æ•ˆæ•°æ®")
    else:
        st.caption("æš‚æ— å†å²å­˜æ¡£")
        
    st.divider()
    # [NEW] æ¸…ç©º/é‡ç½®æŒ‰é’®
    if st.button("ğŸ—‘ï¸ æ¸…ç©ºå½“å‰è¿›åº¦ (é‡æ–°å¼€å§‹)", type="secondary", help="è¿™å°†æ¸…ç©ºæ‰€æœ‰å·²ç”Ÿæˆçš„ç¼–ç ç»“æœï¼Œå…è®¸ä½ ä»å¤´å¼€å§‹è¿è¡Œã€‚"):
        st.session_state.open_codes = pd.DataFrame(columns=['source_file', 'code', 'quote', 'confidence', 'original_row_index'])
        st.success("å·²æ¸…ç©ºè¿›åº¦ã€‚")
        time.sleep(1)
        st.rerun()

st.title("åŒºåŸŸ2: å¼€æ”¾æ€§ç¼–ç  Promptç”Ÿæˆä¸æ‰§è¡ŒåŒº ğŸ› ï¸")

# =======================================================================
# 3. é…ç½®åŒºåŸŸ
# =======================================================================
with st.container(border=True):
    st.subheader("æ­¥éª¤ 1: é…ç½®æ¨¡å¼ä¸è§„åˆ™")
    
    col_key, col_model = st.columns(2)
    with col_key:
        st.markdown("###### ğŸ”‘ å¯†é’¥é…ç½®")
        api_key_input = st.text_input("DashScope Key (Qwen/DeepSeek/GLM)", type="password", value=st.session_state.get('api_key', ''), label_visibility="collapsed", help="ç”¨äº Qwen, DeepSeek, GLM")
        if api_key_input: st.session_state.api_key = api_key_input
        st.session_state.openai_key = st.text_input("OpenAI Key (GPT-4o)", type="password", value=st.session_state.get('openai_key', ''), help="ç”¨äº GPT-4o")
        st.session_state.gemini_key = st.text_input("Gemini Key (Gemini)", type="password", value=st.session_state.get('gemini_key', ''), help="ç”¨äº Gemini")
        st.markdown("""<small>[è·å–DashScope Key](https://bailian.console.aliyun.com/?tab=model#/api-key)</small>""", unsafe_allow_html=True)
        st.markdown("""<small>[é¢†å–å­¦ç”Ÿ300å…ƒä¼˜æƒ åˆ¸](https://university.aliyun.com/?userCode=r3yteowb)</small>""", unsafe_allow_html=True)
    
    with col_model:
        st.markdown("###### ğŸ§  æ¨¡å‹é€‰æ‹©")
        model_options = {
            "ğŸ‘‘ Qwen-Max (é˜¿é‡Œæ——èˆ°)": "qwen-max",
            "ğŸŒŸ GPT-4o (å…¨çƒæ——èˆ°)": "gpt-4o",
            "ğŸš€ Gemini 2.5 Pro (Google æ——èˆ°)": "gemini-2.5-pro",
            "ğŸ’ GLM-4.6 (æ™ºè°±AIæ——èˆ°)": "glm-4.6",
            "ğŸ”¥ DeepSeek-V3 (é€»è¾‘å¼º)": "deepseek-v3",
            "âš–ï¸ Qwen-Plus (å¹³è¡¡æ¨è)": "qwen-plus",
        }
        model_ids = list(model_options.values())
        try: default_index = model_ids.index(st.session_state.selected_model)
        except ValueError: default_index = 0 
        selected_model_name = st.selectbox("é€‰æ‹©æ¨¡å‹", options=model_options.keys(), index=default_index, label_visibility="collapsed")
        st.session_state.selected_model = model_options[selected_model_name]

    st.divider()
    mode_options = ["1. æ™ºèƒ½å‘å¯¼ (å…¨è‡ªåŠ¨)", "2. å¤–éƒ¨è¾…åŠ© (å‚»ç“œç‰ˆ)", "3. é«˜çº§è‡ªå®šä¹‰ (å®Œå…¨æ‰‹åŠ¨)"]
    st.session_state.prompt_mode = st.radio("é€‰æ‹©å·¥ä½œæ¨¡å¼", mode_options, horizontal=True)

    st.markdown("#### 1. æ ¸å¿ƒç ”ç©¶ä¸»é¢˜")
    core_theme_input = st.text_input("ç ”ç©¶ä¸»é¢˜", value=st.session_state.core_theme, label_visibility="collapsed")
    st.session_state.core_theme = core_theme_input

    # --- æ¨¡å¼ A: æ™ºèƒ½å‘å¯¼ ---
    if st.session_state.prompt_mode == "1. æ™ºèƒ½å‘å¯¼ (å…¨è‡ªåŠ¨)":
        if st.button("ğŸ¤– ä¸€é”®ç”Ÿæˆåˆ¤åˆ«æ ‡å‡†", type="primary"):
            if not st.session_state.api_key: st.error("è¯·è¾“å…¥ DashScope Keyï¼"); st.stop()
            elif not core_theme_input or "è¯·åœ¨" in core_theme_input: st.error("è¯·è¾“å…¥æœ‰æ•ˆä¸»é¢˜ï¼"); st.stop()
            
            with st.spinner("æ­£åœ¨åˆ†æ..."):
                meta_prompt = create_background_meta_prompt(st.session_state.core_theme)
                api_res = call_qwen_api(st.session_state.api_key, st.session_state.selected_model, meta_prompt, temperature=0.3)
                
                if api_res["success"]:
                    st.session_state.total_token_usage += api_res["tokens"]
                    data = extract_json(api_res["text"], start_char='{', end_char='}')
                    if isinstance(data, dict):
                        st.session_state.definition_logic = data.get('definition_logic', '')
                        st.session_state.exclusion_logic = data.get('exclusion_logic', '')
                        st.success("æ ‡å‡†ç”ŸæˆæˆåŠŸï¼è¯·åœ¨ä¸‹æ–¹ç¡®è®¤ã€‚")
                    else: st.error(f"ç”Ÿæˆå¤±è´¥: {data}")
                else: st.error(api_res["error"])

    # --- æ¨¡å¼ B: å¤–éƒ¨è¾…åŠ© (å‚»ç“œç‰ˆ) ---
    elif st.session_state.prompt_mode == "2. å¤–éƒ¨è¾…åŠ© (å‚»ç“œç‰ˆ)":
        st.info("ğŸ“‹ **å‚»ç“œæ¨¡å¼ï¼š** åˆ©ç”¨ç½‘é¡µç‰ˆ AI å¼ºå¤§çš„æ¨ç†èƒ½åŠ›ç”Ÿæˆæ ‡å‡†ï¼Œç„¶åå°†ç»“æœç²˜è´´å›æ¥ã€‚")
        help_prompt = f"""æˆ‘æ­£åœ¨åšå…³äºã€{st.session_state.core_theme}ã€‘çš„æ‰æ ¹ç†è®ºç¼–ç ã€‚
è¯·ä¸ºæˆ‘åˆ¶å®šä¸¤ä¸ªæ ‡å‡†ï¼š1. çº³å…¥æ ‡å‡† (Definition Logic)ï¼šè¯·ç”¨ä¸€å¥è¯å®šä¹‰ï¼Œä»€ä¹ˆæ ·çš„æ–‡æœ¬æ‰ç®—å±äºè¿™ä¸ªä¸»é¢˜ï¼Ÿ 2. æ’é™¤æ ‡å‡† (Exclusion Logic)ï¼šè¯·ç”¨ä¸€å¥è¯å®šä¹‰ï¼Œä»€ä¹ˆæ ·å³ä½¿æ²¾è¾¹ä½†ä¹Ÿå¿…é¡»æ’é™¤çš„å†…å®¹ï¼Ÿ
è¯·ä¸¥æ ¼æŒ‰ç…§ â€œ1. çº³å…¥æ ‡å‡†ï¼š...â€ å’Œ â€œ2. æ’é™¤æ ‡å‡†ï¼š...â€ çš„æ ¼å¼ç›´æ¥ç»™å‡ºè¿™ä¸¤æ®µè¯ï¼Œä¸è¦å…¶ä»–åºŸè¯ã€‚"""
        
        with st.expander("ğŸ“‹ ç‚¹å‡»å±•å¼€ï¼šå¤åˆ¶æ±‚åŠ©æŒ‡ä»¤", expanded=True):
            st.code(help_prompt, language="text")

    # --- æ¨¡å¼ 3: é«˜çº§è‡ªå®šä¹‰ (å®Œå…¨æ‰‹åŠ¨) ---
    else:
        st.warning("ğŸ› ï¸ **ä¸“å®¶æ¨¡å¼ï¼š** æ‚¨å®Œå…¨æ§åˆ¶ Promptã€‚")
        
        uploaded_prompt_file = st.file_uploader("ğŸ“¥ ä¸Šä¼ æ‚¨çš„ Prompt (.txt) æ–‡ä»¶", type=["txt"])
        if uploaded_prompt_file:
            string_data = uploaded_prompt_file.getvalue().decode("utf-8")
            st.session_state.custom_prompt = string_data
            st.success("Prompt æ–‡ä»¶è¯»å–æˆåŠŸï¼")
        
        st.session_state.custom_prompt = st.text_area("å®Œæ•´ Prompt ç¼–è¾‘å™¨ (åŒ…å« {text_to_code})", value=st.session_state.custom_prompt, height=400)
    
    # --- å…¬å…±åŒºåŸŸï¼šæ˜¾ç¤º/ç¼–è¾‘æ ‡å‡† ---
    st.divider()

    if st.session_state.prompt_mode in ["1. æ™ºèƒ½å‘å¯¼ (å…¨è‡ªåŠ¨)", "2. å¤–éƒ¨è¾…åŠ© (å‚»ç“œç‰ˆ)"]:
        col_def, col_exc = st.columns(2)
        with col_def:
            st.session_state.definition_logic = st.text_area("âœ… çº³å…¥æ ‡å‡† (Definition)", value=st.session_state.definition_logic, height=100)
        with col_exc:
            st.session_state.exclusion_logic = st.text_area("âŒ æ’é™¤æ ‡å‡† (Exclusion)", value=st.session_state.exclusion_logic, height=100)
            
    # --- Prompt Saving Feature ---
    prompt_to_save = ""
    if st.session_state.prompt_mode == "3. é«˜çº§è‡ªå®šä¹‰ (å®Œå…¨æ‰‹åŠ¨)":
        prompt_to_save = st.session_state.custom_prompt
        save_label = "ğŸ’¾ ä¸‹è½½è‡ªå®šä¹‰ Prompt (.txt)"
        filename_prefix = "CustomPrompt"
    elif st.session_state.definition_logic and st.session_state.exclusion_logic:
        prompt_to_save = create_final_coding_prompt(
            st.session_state.core_theme, 
            st.session_state.definition_logic, 
            st.session_state.exclusion_logic, 
            "{text_to_code}" 
        )
        save_label = "ğŸ’¾ ä¸‹è½½æœ€ç»ˆç¼–ç  Prompt (.txt)"
        filename_prefix = "FinalCodingPrompt"
    
    if prompt_to_save:
        timestamp = time.strftime("%Y%m%d%H%M")
        filename = f"{filename_prefix}_{st.session_state.core_theme}_{timestamp}.txt"
        st.download_button(
            label=save_label,
            data=prompt_to_save,
            file_name=filename,
            mime="text/plain",
            key="download_final_prompt",
            type="secondary"
        )


# =======================================================================
# 4. æ‰§è¡ŒåŒºåŸŸ
# =======================================================================
can_run = False
if st.session_state.prompt_mode == "3. é«˜çº§è‡ªå®šä¹‰ (å®Œå…¨æ‰‹åŠ¨)":
    can_run = "{text_to_code}" in st.session_state.custom_prompt
elif st.session_state.definition_logic and st.session_state.exclusion_logic:
    can_run = True

if can_run:
    if df is None:
        st.warning("âš ï¸ è¯·å…ˆåœ¨â€œ1_Data_Uploadâ€é¡µé¢ä¸Šä¼ æ•°æ®ã€‚")
        st.stop()
        
    with st.container(border=True):
        st.subheader("æ­¥éª¤ 2: æ‰§è¡Œå¼€æ”¾æ€§ç¼–ç ")
        st.dataframe(df, height=150)
        
        temperature_input = st.slider("æ¸©åº¦ (Temperature) - æ¨è 0.1", 0.0, 1.0, value=st.session_state.temperature, step=0.05)
        st.session_state.temperature = temperature_input
        
        with st.expander(f"ç‚¹å‡»æŸ¥çœ‹ Prompt é¢„è§ˆ (å°†å‘é€ç»™ {st.session_state.selected_model})"):
            if st.session_state.prompt_mode == "3. é«˜çº§è‡ªå®šä¹‰ (å®Œå…¨æ‰‹åŠ¨)":
                st.code(st.session_state.custom_prompt, language="markdown")
            else:
                preview_prompt = create_final_coding_prompt(st.session_state.core_theme, st.session_state.definition_logic, st.session_state.exclusion_logic, "[å¾…å¤„ç†æ–‡æœ¬]")
                st.code(preview_prompt, language="markdown")

        col1, col2 = st.columns(2)
        with col1:
            num_to_test = st.number_input("æµ‹è¯•æ¡æ•°", 1, 50, 3)
            if st.button("â–¶ï¸ æµ‹è¯•è¿è¡Œ"):
                if not st.session_state.api_key and not st.session_state.openai_key and not st.session_state.gemini_key: st.error("è¯·è‡³å°‘è¾“å…¥ä¸€ä¸ª API å¯†é’¥ï¼"); st.stop()
                with st.spinner("æµ‹è¯•ä¸­..."):
                    test_results = []
                    # [FIX] æµ‹è¯•è¿è¡Œæ—¶ä¹Ÿè¦è€ƒè™‘æ˜¯å¦å·²å¤„ç†ï¼Ÿé€šå¸¸æµ‹è¯•è¿è¡Œä¸éœ€è¦æŒä¹…åŒ–ä¿å­˜
                    for i, row in df.head(num_to_test).iterrows():
                        if st.session_state.prompt_mode == "3. é«˜çº§è‡ªå®šä¹‰ (å®Œå…¨æ‰‹åŠ¨)":
                            prompt = st.session_state.custom_prompt.format(text_to_code=row['text_content'])
                        else:
                            prompt = create_final_coding_prompt(st.session_state.core_theme, st.session_state.definition_logic, st.session_state.exclusion_logic, row['text_content'])
                        
                        res = call_qwen_api(st.session_state.api_key, st.session_state.selected_model, prompt, st.session_state.temperature)
                        if res["success"]:
                            st.session_state.total_token_usage += res["tokens"]
                            codes = extract_json(res["text"], start_char='[', end_char=']')
                            
                            clean_codes = []
                            if isinstance(codes, list):
                                for c in codes:
                                    if isinstance(c, dict) and 'code' in c: 
                                        if 'quote' not in c: c['quote'] = "ï¼ˆAIæœªè¿”å›Quoteï¼‰"
                                        if 'confidence' not in c: c['confidence'] = 0
                                        clean_codes.append(c)
                                    elif isinstance(c, str):
                                        clean_codes.append({"code": c, "quote": "ï¼ˆAIæœªè¿”å›Quoteï¼‰", "confidence": 0})
                            test_results.extend(clean_codes)
                        else: st.error(res["error"])
                    st.dataframe(test_results)

        with col2:
            st.markdown(f"**ç´¯è®¡Token:** `{st.session_state.total_token_usage}`")
            
            is_running = st.session_state.get('is_processing', False)
            if is_running:
                if st.button("â¹ï¸ åœæ­¢å¤„ç†", type="primary"): 
                    st.session_state.stop_requested = True; st.rerun()
            else:
                if st.button("ğŸš€ æ‰¹é‡å¤„ç† (æ™ºèƒ½è·³è¿‡)", type="primary"): 
                    st.session_state.is_processing = True; st.session_state.stop_requested = False; st.rerun()

            if st.session_state.get('is_processing', False):
                progress_bar = st.progress(0, text="å‡†å¤‡ä¸­...")
                log_container = st.empty()
                log_messages = []
                
                # [CRITICAL FIX] æ™ºèƒ½è·³è¿‡é€»è¾‘ï¼šåŸºäº original_row_index
                # ç¡®ä¿ 'original_row_index' å­˜åœ¨ä¸”ä¸ºæ•´æ•°ç±»å‹ï¼Œé¿å…ç±»å‹ä¸åŒ¹é…å¯¼è‡´ isin å¤±æ•ˆ
                if 'original_row_index' in st.session_state.open_codes.columns:
                    # å°†åˆ—è½¬ä¸ºæ•°å€¼å‹ï¼Œå¤„ç†å¯èƒ½çš„ None/NaN
                    processed_series = pd.to_numeric(st.session_state.open_codes['original_row_index'], errors='coerce').dropna()
                    processed = processed_series.unique()
                else: processed = []
                
                to_process = df[~df.index.isin(processed)]
                total = len(to_process)
                
                if total == 0:
                    st.success("ğŸ‰ æ‰€æœ‰æ•°æ®å·²å¤„ç†å®Œæ¯•ï¼ˆåŒ…å«å†å²æ¢å¤çš„æ•°æ®ï¼‰ã€‚")
                    st.session_state.is_processing = False
                    st.rerun()

                count = 0
                for i, row in to_process.iterrows():
                    if st.session_state.stop_requested: st.error("å·²åœæ­¢"); st.session_state.is_processing = False; st.rerun(); break
                    
                    if st.session_state.prompt_mode == "3. é«˜çº§è‡ªå®šä¹‰ (å®Œå…¨æ‰‹åŠ¨)":
                        prompt = st.session_state.custom_prompt.format(text_to_code=row['text_content'])
                    else:
                        prompt = create_final_coding_prompt(st.session_state.core_theme, st.session_state.definition_logic, st.session_state.exclusion_logic, row['text_content'])
                    
                    res = call_qwen_api(st.session_state.api_key, st.session_state.selected_model, prompt, st.session_state.temperature)
                    
                    log_msg = ""
                    if res["success"]:
                        st.session_state.total_token_usage += res["tokens"]
                        codes = extract_json(res["text"], start_char='[', end_char=']')
                        
                        clean_codes = []
                        if isinstance(codes, list):
                            for c in codes:
                                if isinstance(c, dict) and 'code' in c:
                                    if 'quote' not in c: c['quote'] = "ï¼ˆAIæœªè¿”å›Quoteï¼‰"
                                    if 'confidence' not in c: c['confidence'] = 0
                                    clean_codes.append(c)
                                elif isinstance(c, str):
                                    clean_codes.append({"code": c, "quote": "ï¼ˆAIæœªè¿”å›Quoteï¼‰", "confidence": 0})

                        if clean_codes:
                            code_str = ", ".join([f"[{c['code']} ({c['confidence']}/5)]" for c in clean_codes])
                            log_msg = f"âœ… è¡Œ{i} | ğŸª™{res['tokens']} | ğŸ·ï¸ {code_str}"
                            
                            # 1. æ›´æ–° Session State DataFrame
                            new_df = pd.DataFrame(clean_codes)
                            new_df['source_file'] = row.get('source_file', 'unknown')
                            new_df['original_row_index'] = i
                            st.session_state.open_codes = pd.concat([st.session_state.open_codes, new_df], ignore_index=True)
                            
                            # 2. [NEW] ç«‹å³æŒä¹…åŒ–ä¿å­˜åˆ° JSONL (Recovery)
                            record_to_save = {
                                "original_row_index": i,
                                "source_file": row.get('source_file', 'unknown'),
                                "text_content": row['text_content'], # åŸå§‹æ–‡æœ¬ä¹Ÿå­˜ä¸€ä¸‹ï¼Œæ–¹ä¾¿æ ¸å¯¹
                                "generated_codes": clean_codes,
                                "model": st.session_state.selected_model
                            }
                            filename = get_current_filename(st.session_state.core_theme)
                            save_record_to_jsonl(record_to_save, filename)
                            
                        else: 
                            log_msg = f"âšª è¡Œ{i} | ğŸª™{res['tokens']} | æ— ç›¸å…³å†…å®¹"
                    else: 
                        log_msg = f"âŒ APIé”™è¯¯: {res['error']}"

                    if log_msg: log_messages.append(log_msg)
                    log_container.text_area("æ—¥å¿—", value="\n".join(reversed(log_messages)), height=250)
                    
                    count += 1
                    progress_bar.progress(count / total, text=f"è¿›åº¦: {count}/{total} (æ­£åœ¨å¤„ç†ç¬¬ {i} è¡Œ)")
                
                if not st.session_state.stop_requested:
                    st.success("å®Œæˆï¼"); st.session_state.is_processing = False; st.rerun()

# =======================================================================
# 5. ç»“æœé¢„è§ˆ
# =======================================================================
if not st.session_state.open_codes.empty:
    with st.container(border=True):
        st.subheader("æ­¥éª¤ 3: ç»“æœé¢„è§ˆä¸ä¿å­˜")
        
        cols = ['source_file', 'code', 'quote', 'confidence', 'original_row_index']
        for c in cols: 
            if c not in st.session_state.open_codes.columns: st.session_state.open_codes[c] = None
            
        edited = st.data_editor(
            st.session_state.open_codes, 
            column_order=['source_file', 'code', 'quote', 'confidence'],
            disabled=['source_file'],
            num_rows="dynamic", key="editor", height=400
        )
        st.session_state.open_codes = edited
        
        st.markdown("#### ä¿å­˜é¡¹ç›®")
        meta_bg = "Custom" if st.session_state.prompt_mode == "3. é«˜çº§è‡ªå®šä¹‰ (å®Œå…¨æ‰‹åŠ¨)" else f"çº³å…¥ï¼š{st.session_state.definition_logic}\næ’é™¤ï¼š{st.session_state.exclusion_logic}"
            
        excel_data = to_excel(
            df, 
            edited, 
            pd.DataFrame({"core_theme":[st.session_state.core_theme], "bg":[meta_bg]})
        )
        st.download_button("ğŸš€ ä¸‹è½½é¡¹ç›® (.xlsx)", data=excel_data, file_name=f"Project_{st.session_state.core_theme}.xlsx", mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet", type="primary")
        st.page_link("pages/3_Axial_Coding.py", label="ä¸‹ä¸€æ­¥ (è½´å¿ƒç¼–ç )", icon="â¡ï¸")

